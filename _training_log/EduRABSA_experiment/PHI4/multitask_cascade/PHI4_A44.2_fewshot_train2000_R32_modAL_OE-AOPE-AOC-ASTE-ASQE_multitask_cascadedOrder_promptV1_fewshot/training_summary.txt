
================================================================================
TRAINING SUMMARY - 2025-08-03 23:14:02
================================================================================



================================================================================
TRAINING CONFIGURATION:
================================================================================

output_dir: _lora_checkpoints/experiment/PHI4_A44.2_fewshot_train2000_R32_modAL_OE-AOPE-AOC-ASTE-ASQE_multitask_cascadedOrder_promptV1_fewshot/
overwrite_output_dir: False
do_train: False
do_eval: True
do_predict: False
eval_strategy: steps
prediction_loss_only: False
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
per_gpu_train_batch_size: None
per_gpu_eval_batch_size: None
gradient_accumulation_steps: 10
eval_accumulation_steps: 10
eval_delay: 0
torch_empty_cache_steps: None
learning_rate: 0.00025
weight_decay: 0.004
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1e-08
max_grad_norm: 1.0
num_train_epochs: 3
max_steps: -1
lr_scheduler_type: cosine
lr_scheduler_kwargs: {}
warmup_ratio: 0.1
warmup_steps: 0
log_level: warning
log_level_replica: warning
log_on_each_node: True
logging_dir: _training_log/experiment/PHI4_A44.2_fewshot_train2000_R32_modAL_OE-AOPE-AOC-ASTE-ASQE_multitask_cascadedOrder_promptV1_fewshot/
logging_strategy: steps
logging_first_step: True
logging_steps: 20
logging_nan_inf_filter: True
save_strategy: steps
save_steps: 50
save_total_limit: 6
save_safetensors: True
save_on_each_node: False
save_only_model: False
restore_callback_states_from_checkpoint: False
no_cuda: False
use_cpu: False
use_mps_device: False
seed: 73
data_seed: None
jit_mode_eval: False
use_ipex: False
bf16: True
fp16: False
fp16_opt_level: O1
half_precision_backend: auto
bf16_full_eval: False
fp16_full_eval: False
tf32: None
local_rank: 0
ddp_backend: None
tpu_num_cores: None
tpu_metrics_debug: False
debug: []
dataloader_drop_last: False
eval_steps: 50
dataloader_num_workers: 0
dataloader_prefetch_factor: None
past_index: -1
run_name: _lora_checkpoints/experiment/PHI4_A44.2_fewshot_train2000_R32_modAL_OE-AOPE-AOC-ASTE-ASQE_multitask_cascadedOrder_promptV1_fewshot/
disable_tqdm: False
remove_unused_columns: True
label_names: None
load_best_model_at_end: True
metric_for_best_model: eval_rougeL_fmeasure
greater_is_better: True
ignore_data_skip: False
fsdp: []
fsdp_min_num_params: 0
fsdp_config: {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
fsdp_transformer_layer_cls_to_wrap: None
accelerator_config: {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}
deepspeed: None
label_smoothing_factor: 0.08
optim: adamw_torch
optim_args: None
adafactor: False
group_by_length: False
length_column_name: length
report_to: ['tensorboard']
ddp_find_unused_parameters: None
ddp_bucket_cap_mb: None
ddp_broadcast_buffers: None
dataloader_pin_memory: True
dataloader_persistent_workers: False
skip_memory_metrics: True
use_legacy_prediction_loop: False
push_to_hub: False
resume_from_checkpoint: None
hub_model_id: None
hub_strategy: every_save
hub_token: <HUB_TOKEN>
hub_private_repo: None
hub_always_push: False
gradient_checkpointing: True
gradient_checkpointing_kwargs: {'use_reentrant': True}
include_inputs_for_metrics: False
include_for_metrics: []
eval_do_concat_batches: True
fp16_backend: auto
evaluation_strategy: None
push_to_hub_model_id: None
push_to_hub_organization: None
push_to_hub_token: <PUSH_TO_HUB_TOKEN>
mp_parameters: 
auto_find_batch_size: False
full_determinism: False
torchdynamo: None
ray_scope: last
ddp_timeout: 1800
torch_compile: False
torch_compile_backend: None
torch_compile_mode: None
dispatch_batches: None
split_batches: None
include_tokens_per_second: False
include_num_input_tokens_seen: False
neftune_noise_alpha: None
optim_target_modules: None
batch_eval_metrics: False
eval_on_start: False
use_liger_kernel: False
eval_use_gather_object: False
average_tokens_across_devices: False
model_init_kwargs: None
use_liger: False
dataset_text_field: text
dataset_kwargs: None
dataset_num_proc: None
max_seq_length: 3000
packing: False
eval_packing: None
dataset_batch_size: None
num_of_sequences: None
chars_per_token: <CHARS_PER_TOKEN>


================================================================================
TRAINING LOG HISTORY:
================================================================================

Step 1:
  loss: 49.236000
  grad_norm: 518.971619
  learning_rate: 0.000001
  epoch: 0.001000
  step: 1

Step 2:
  loss: 41.189400
  grad_norm: 44.985519
  learning_rate: 0.000017
  epoch: 0.020000
  step: 20

Step 3:
  loss: 24.194100
  grad_norm: 17.363089
  learning_rate: 0.000033
  epoch: 0.040000
  step: 40

Step 4:
  eval_loss: 1.592339
  eval_rouge1_precision: 0.942384
  eval_rouge1_recall: 0.933142
  eval_rouge1_fmeasure: 0.937716
  eval_rouge2_precision: 0.895110
  eval_rouge2_recall: 0.886572
  eval_rouge2_fmeasure: 0.890798
  eval_rougeL_precision: 0.930119
  eval_rougeL_recall: 0.921094
  eval_rougeL_fmeasure: 0.925561
  eval_rougeLsum_precision: 0.934619
  eval_rougeLsum_recall: 0.925521
  eval_rougeLsum_fmeasure: 0.930024
  eval_rouge1_fbeta_1.5: 0.935967
  eval_rouge2_fbeta_1.5: 0.889182
  eval_rougeL_fbeta_1.5: 0.923852
  eval_rougeLsum_fbeta_1.5: 0.928301
  eval_runtime: 212.559000
  eval_samples_per_second: 4.705000
  eval_steps_per_second: 4.705000
  epoch: 0.050000
  step: 50

Step 5:
  loss: 16.236000
  grad_norm: 6.204281
  learning_rate: 0.000050
  epoch: 0.060000
  step: 60

Step 6:
  loss: 15.448400
  grad_norm: 40.016029
  learning_rate: 0.000067
  epoch: 0.080000
  step: 80

Step 7:
  loss: 15.118300
  grad_norm: 17.420364
  learning_rate: 0.000083
  epoch: 0.100000
  step: 100

Step 8:
  eval_loss: 1.510416
  eval_rouge1_precision: 0.943603
  eval_rouge1_recall: 0.936770
  eval_rouge1_fmeasure: 0.940154
  eval_rouge2_precision: 0.898155
  eval_rouge2_recall: 0.891855
  eval_rouge2_fmeasure: 0.894976
  eval_rougeL_precision: 0.931890
  eval_rougeL_recall: 0.925222
  eval_rougeL_fmeasure: 0.928525
  eval_rougeLsum_precision: 0.936127
  eval_rougeLsum_recall: 0.929406
  eval_rougeLsum_fmeasure: 0.932735
  eval_rouge1_fbeta_1.5: 0.938862
  eval_rouge2_fbeta_1.5: 0.893784
  eval_rougeL_fbeta_1.5: 0.927264
  eval_rougeLsum_fbeta_1.5: 0.931463
  eval_runtime: 207.174300
  eval_samples_per_second: 4.827000
  eval_steps_per_second: 4.827000
  epoch: 0.100000
  step: 100

Step 9:
  loss: 15.092200
  grad_norm: 16.899815
  learning_rate: 0.000100
  epoch: 0.120000
  step: 120

Step 10:
  loss: 15.003300
  grad_norm: 8.098777
  learning_rate: 0.000117
  epoch: 0.140000
  step: 140

Step 11:
  eval_loss: 1.513768
  eval_rouge1_precision: 0.946473
  eval_rouge1_recall: 0.937290
  eval_rouge1_fmeasure: 0.941835
  eval_rouge2_precision: 0.900895
  eval_rouge2_recall: 0.892401
  eval_rouge2_fmeasure: 0.896606
  eval_rougeL_precision: 0.934400
  eval_rougeL_recall: 0.925436
  eval_rougeL_fmeasure: 0.929874
  eval_rougeLsum_precision: 0.938881
  eval_rougeLsum_recall: 0.929844
  eval_rougeLsum_fmeasure: 0.934317
  eval_rouge1_fbeta_1.5: 0.940096
  eval_rouge2_fbeta_1.5: 0.894997
  eval_rougeL_fbeta_1.5: 0.928176
  eval_rougeLsum_fbeta_1.5: 0.932606
  eval_runtime: 209.745800
  eval_samples_per_second: 4.768000
  eval_steps_per_second: 4.768000
  epoch: 0.150000
  step: 150

Step 12:
  loss: 15.009200
  grad_norm: 12.887470
  learning_rate: 0.000133
  epoch: 0.160000
  step: 160

Step 13:
  loss: 15.027700
  grad_norm: 7.514622
  learning_rate: 0.000150
  epoch: 0.180000
  step: 180

Step 14:
  loss: 14.874100
  grad_norm: 5.255401
  learning_rate: 0.000167
  epoch: 0.200000
  step: 200

Step 15:
  eval_loss: 1.496410
  eval_rouge1_precision: 0.942630
  eval_rouge1_recall: 0.936404
  eval_rouge1_fmeasure: 0.939488
  eval_rouge2_precision: 0.896934
  eval_rouge2_recall: 0.891214
  eval_rouge2_fmeasure: 0.894048
  eval_rougeL_precision: 0.930750
  eval_rougeL_recall: 0.924688
  eval_rougeL_fmeasure: 0.927690
  eval_rougeLsum_precision: 0.935150
  eval_rougeLsum_recall: 0.929034
  eval_rougeLsum_fmeasure: 0.932063
  eval_rouge1_fbeta_1.5: 0.938311
  eval_rouge2_fbeta_1.5: 0.892966
  eval_rougeL_fbeta_1.5: 0.926544
  eval_rougeLsum_fbeta_1.5: 0.930907
  eval_runtime: 207.979400
  eval_samples_per_second: 4.808000
  eval_steps_per_second: 4.808000
  epoch: 0.200000
  step: 200

Step 16:
  loss: 15.077800
  grad_norm: 4.519039
  learning_rate: 0.000183
  epoch: 0.220000
  step: 220

Step 17:
  loss: 14.830200
  grad_norm: 5.731173
  learning_rate: 0.000200
  epoch: 0.240000
  step: 240

Step 18:
  eval_loss: 1.493971
  eval_rouge1_precision: 0.944249
  eval_rouge1_recall: 0.935664
  eval_rouge1_fmeasure: 0.939910
  eval_rouge2_precision: 0.899360
  eval_rouge2_recall: 0.891439
  eval_rouge2_fmeasure: 0.895357
  eval_rougeL_precision: 0.932356
  eval_rougeL_recall: 0.923987
  eval_rougeL_fmeasure: 0.928126
  eval_rougeLsum_precision: 0.936589
  eval_rougeLsum_recall: 0.928151
  eval_rougeLsum_fmeasure: 0.932324
  eval_rouge1_fbeta_1.5: 0.938289
  eval_rouge2_fbeta_1.5: 0.893861
  eval_rougeL_fbeta_1.5: 0.926546
  eval_rougeLsum_fbeta_1.5: 0.930731
  eval_runtime: 207.995800
  eval_samples_per_second: 4.808000
  eval_steps_per_second: 4.808000
  epoch: 0.250000
  step: 250

Step 19:
  loss: 14.533900
  grad_norm: 8.104875
  learning_rate: 0.000217
  epoch: 0.260000
  step: 260

Step 20:
  loss: 14.794000
  grad_norm: 11.461810
  learning_rate: 0.000233
  epoch: 0.280000
  step: 280

Step 21:
  loss: 14.821100
  grad_norm: 6.253781
  learning_rate: 0.000250
  epoch: 0.300000
  step: 300

Step 22:
  eval_loss: 1.499205
  eval_rouge1_precision: 0.942454
  eval_rouge1_recall: 0.936743
  eval_rouge1_fmeasure: 0.939573
  eval_rouge2_precision: 0.897185
  eval_rouge2_recall: 0.891884
  eval_rouge2_fmeasure: 0.894511
  eval_rougeL_precision: 0.930704
  eval_rougeL_recall: 0.925118
  eval_rougeL_fmeasure: 0.927887
  eval_rougeLsum_precision: 0.935078
  eval_rougeLsum_recall: 0.929450
  eval_rougeLsum_fmeasure: 0.932240
  eval_rouge1_fbeta_1.5: 0.938493
  eval_rouge2_fbeta_1.5: 0.893508
  eval_rougeL_fbeta_1.5: 0.926830
  eval_rougeLsum_fbeta_1.5: 0.931175
  eval_runtime: 209.382700
  eval_samples_per_second: 4.776000
  eval_steps_per_second: 4.776000
  epoch: 0.300000
  step: 300

Step 23:
  loss: 14.586500
  grad_norm: 5.118767
  learning_rate: 0.000250
  epoch: 0.320000
  step: 320

Step 24:
  loss: 14.659000
  grad_norm: 6.852188
  learning_rate: 0.000250
  epoch: 0.340000
  step: 340

Step 25:
  eval_loss: 1.506700
  eval_rouge1_precision: 0.942997
  eval_rouge1_recall: 0.934350
  eval_rouge1_fmeasure: 0.938628
  eval_rouge2_precision: 0.898318
  eval_rouge2_recall: 0.890315
  eval_rouge2_fmeasure: 0.894276
  eval_rougeL_precision: 0.931071
  eval_rougeL_recall: 0.922631
  eval_rougeL_fmeasure: 0.926807
  eval_rougeLsum_precision: 0.935307
  eval_rougeLsum_recall: 0.926799
  eval_rougeLsum_fmeasure: 0.931008
  eval_rouge1_fbeta_1.5: 0.936994
  eval_rouge2_fbeta_1.5: 0.892763
  eval_rougeL_fbeta_1.5: 0.925212
  eval_rougeLsum_fbeta_1.5: 0.929400
  eval_runtime: 207.359900
  eval_samples_per_second: 4.823000
  eval_steps_per_second: 4.823000
  epoch: 0.350000
  step: 350

Step 26:
  loss: 14.505200
  grad_norm: 14.572143
  learning_rate: 0.000250
  epoch: 0.360000
  step: 360

Step 27:
  loss: 14.557500
  grad_norm: 3.627094
  learning_rate: 0.000249
  epoch: 0.380000
  step: 380

Step 28:
  loss: 14.583500
  grad_norm: 3.629150
  learning_rate: 0.000249
  epoch: 0.400000
  step: 400

Step 29:
  eval_loss: 1.494430
  eval_rouge1_precision: 0.942457
  eval_rouge1_recall: 0.935804
  eval_rouge1_fmeasure: 0.939096
  eval_rouge2_precision: 0.897740
  eval_rouge2_recall: 0.891623
  eval_rouge2_fmeasure: 0.894650
  eval_rougeL_precision: 0.930283
  eval_rougeL_recall: 0.923808
  eval_rougeL_fmeasure: 0.927012
  eval_rougeLsum_precision: 0.934706
  eval_rougeLsum_recall: 0.928171
  eval_rougeLsum_fmeasure: 0.931404
  eval_rouge1_fbeta_1.5: 0.937841
  eval_rouge2_fbeta_1.5: 0.893496
  eval_rougeL_fbeta_1.5: 0.925790
  eval_rougeLsum_fbeta_1.5: 0.930172
  eval_runtime: 210.295100
  eval_samples_per_second: 4.755000
  eval_steps_per_second: 4.755000
  epoch: 0.400000
  step: 400

Step 30:
  train_runtime: 3427.753100
  train_samples_per_second: 8.752000
  train_steps_per_second: 0.875000
  total_flos: 55412318146166784.000000
  train_loss: 16.727188
  epoch: 0.400000
  step: 400
