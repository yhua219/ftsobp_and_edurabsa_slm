{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# <font color='yellowgreen'>Merged model inference + FTS-OBP evaluation</font>",
   "id": "e781bc3c0109b62b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:44.999899Z",
     "start_time": "2025-11-06T10:24:41.831620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "from pynvml import *\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "from util.prompt import all_prompt_dict\n",
    "from util.absa_evaluator import ABSAEvaluator\n",
    "from util.dictToExcel import *\n",
    "\n",
    "from datetime import date\n",
    "today = date.today().strftime(\"%Y-%m-%d\") \n",
    "\n",
    "#===================================================================================\n",
    "# User input area\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "##########################################\n",
    "# True = Use 4 examples/task (total = 20);   False = use the 300 example/task full test dataset (total = 1500)\n",
    "try_small_sample_with_this_script = True  \n",
    "##########################################\n",
    "\n",
    "use_phi4 = True  # if False, use Qwen2.5-1.5B-Instruct; otherwise use Phi-4-mini-instruct\n",
    "\n",
    "# model_checkpoint_path = '../downloaded_from_HF/EduRABSA_SLM_v1_SLERP_phi4mini'\n",
    "model_checkpoint_path = '../model/LORA_SFT/merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot'\n",
    "\n",
    "task_list = ['OE', 'AOPE', 'AOC', 'ASTE', 'ASQE']\n",
    "prompt_version = 'V1_fewshot' # 'V1_zeroshot'\n",
    "\n",
    "model_str = 'PHI4' if use_phi4 else 'QW2.5'\n",
    "\n",
    "is_multitask = len(task_list) > 1\n",
    "\n",
    "# Set up evaluator and evaluation output dict\n",
    "prompt_dict = all_prompt_dict[prompt_version]\n",
    "evaluator = ABSAEvaluator(prompt_dict, equal_weights=True, partial_category_score=0.3, allow_partial_category_for_unit_match=False)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "handle_format_error = False  # If False, incorrect output format, e.g. additional characters around array '[', ']' will not be handled. \n",
    "\n",
    "dataset_subdir = '4_shot_prompt' if prompt_version == 'V1_fewshot' else '0_shot_prompt'\n",
    "local_DEV_TEST_hf_dataset_dir = f\"../datasets/EduRABSA/EduRABSA_SLM_v1_Test_data/{dataset_subdir}\"\n",
    "\n",
    "#============================================================================================================================================\n",
    "# More stable parameters below:\n",
    "#============================================================================================================================================\n",
    "\n",
    "evaluation_model_to_gpu = True\n",
    "evaluation_device_map = {\"\": 0} if evaluation_model_to_gpu else 'cpu'\n",
    "torch_dtype = torch.bfloat16\n",
    "use_deepspeed = False\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "# End of main user input area (pls also adjust configs below if needed)\n",
    "#===================================================================================\n",
    "# Auto-produced strings, no need to edit\n",
    "#. . . . . . . . . . . . . . . . . . . . . . . .\n",
    "# accelerator_config = \"config/accelerate_config_DS.json\" if use_deepspeed else \"config/accelerate_config_noDS.json\"\n",
    "\n",
    "finetuned_model_id = model_checkpoint_path.replace('../uploaded_to_HF/','').replace('../model/LORA_SFT/','').split(' ')[0].strip()\n",
    "\n",
    "test_input_dict_dir = f\"../OUTPUTS/OUTPUT_1_final_test_output_files/_demo/test_input_{finetuned_model_id}_({today}).py\"\n",
    "test_xlsx_file_dir = f\"../OUTPUTS/OUTPUT_2a_final_test_output_FTS-0BP_evaluation/_demo/test_results_{finetuned_model_id}_({today}).xlsx\"\n",
    "\n",
    "#===============================================\n",
    "# More settings for manual editing\n",
    "\n",
    "evaluation_setting = {\n",
    "    \"eval_setting_view_sample\": True,\n",
    "    \"eval_setting_view_size\": 50,\n",
    "    \"handle_format_error\": handle_format_error,\n",
    "    \"eval_setting_show_table\": False,\n",
    "}\n",
    "\n",
    "# inference config for evaluation\n",
    "generation_args = {\"max_new_tokens\": 1024,\n",
    "                   \"return_full_text\": False,\n",
    "                   \"temperature\": None, # or a float after setting 'do_sample=True' \n",
    "                   \"top_p\": None,\n",
    "                   \"top_k\": None,\n",
    "                   \"do_sample\": False\n",
    "                   }\n",
    "\n",
    "evaluation_model_kwargs = {\n",
    "    'use_cache': False,\n",
    "    'trust_remote_code': False,  # See issue here: https://github.com/huggingface/transformers/issues/32365\n",
    "    'attn_implementation': 'flash_attention_2',\n",
    "    'torch_dtype': torch_dtype,  # loaded pre-trained model torch dtype\n",
    "    'device_map': evaluation_device_map,  # Must be None if using DeepSpeed Zero3\n",
    "}\n",
    "\n",
    "#===================================================================================\n",
    "sheetname_df_dict = dict()\n",
    "\n",
    "#===============================================\n",
    "# Set up accelerator for training\n",
    "# os.environ[\"ACCELERATE_CONFIG_FILE\"] = accelerator_config\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "accelerator = Accelerator(cpu=not evaluation_model_to_gpu)\n",
    "device = accelerator.device\n",
    "print(f\"\\033[32m\\n{'=' * 20}\\n Device =  {device} \\n{'=' * 20}\\033[0m\\n\")\n",
    "\n",
    "#===============================================\n",
    "# Check GPU memory (baseline usage)\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"\\033[35mGPU memory occupied: {info.used//1024**2} MB\\033[0m\\n\")\n",
    "\n",
    "print_gpu_utilization()\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # This is key for releasing GPU memory\n",
    "torch.cuda.synchronize()  # Ensure all CUDA operations are complete\n",
    "# Check GPU memory (baseline usage)\n",
    "print_gpu_utilization()\n",
    "\n",
    "#===============================================\n",
    "#===============================================\n",
    "green_bg = '\\033[1;30;42m'\n",
    "red_bg = '\\033[1;30;41m'\n",
    "yellow_bg = '\\033[1;30;43m'\n",
    "blue_bg = '\\033[1;30;44m'\n",
    "pink_bg = '\\033[1;30;45m'\n",
    "\n",
    "print(f\"\\nUsing model:           {green_bg if use_phi4 else yellow_bg}Merged_LoRA_{model_str}\\033[0m\\n\\n\"\n",
    "      \n",
    "      f\"is_multitask:          {blue_bg if is_multitask else pink_bg}{is_multitask}\\033[0m\\n\\n\"\n",
    "      \n",
    "      f\"merged model dir:       \\033[33m{model_checkpoint_path}\\033[0m\\n\\n\"\n",
    "      \n",
    "      f\"evaluate on GPU:       \\033[36m{evaluation_model_to_gpu}\\033[0m\\n\\n\"\n",
    "\n",
    "      f\"Local TEST dataset     \\033[37m{local_DEV_TEST_hf_dataset_dir}\\033[0m\\n\\n\"\n",
    "      \n",
    "      f\"TEST input dict dir:   \\033[34m{test_input_dict_dir}\\033[0m\\n\"\n",
    "      f\"TEST output dir:       \\033[32m{test_xlsx_file_dir}\\033[0m\\n\\n\"\n",
    "      )"
   ],
   "id": "3a62acfc182e1e65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m\n",
      "====================\n",
      " Device =  cuda \n",
      "====================\u001B[0m\n",
      "\n",
      "\u001B[35mGPU memory occupied: 1086 MB\u001B[0m\n",
      "\n",
      "\u001B[35mGPU memory occupied: 1342 MB\u001B[0m\n",
      "\n",
      "\n",
      "Using model:           \u001B[1;30;42mMerged_LoRA_PHI4\u001B[0m\n",
      "\n",
      "is_multitask:          \u001B[1;30;44mTrue\u001B[0m\n",
      "\n",
      "merged model dir:       \u001B[33m../model/LORA_SFT/merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot\u001B[0m\n",
      "\n",
      "evaluate on GPU:       \u001B[36mTrue\u001B[0m\n",
      "\n",
      "Local TEST dataset     \u001B[37m../datasets/EduRABSA/EduRABSA_SLM_v1_Test_data/4_shot_prompt\u001B[0m\n",
      "\n",
      "TEST input dict dir:   \u001B[34m../OUTPUTS/OUTPUT_1_final_test_output_files/_demo/test_input_merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot_(2025-11-06).py\u001B[0m\n",
      "TEST output dir:       \u001B[32m../OUTPUTS/OUTPUT_2a_final_test_output_FTS-0BP_evaluation/_demo/test_results_merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot_(2025-11-06).xlsx\u001B[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# <font color='cornflowerblue'>Load tokenizer & add custom tokens</font>"
   ],
   "id": "f40a9e30b6427397"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:45.368570Z",
     "start_time": "2025-11-06T10:24:45.009132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################\n",
    "# Load tokenizer \n",
    "################################\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_path)\n",
    "tokenizer.model_max_length = generation_args['max_new_tokens']\n",
    "# tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "# tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'\n",
    "\n",
    "pre_len = len(tokenizer)\n",
    "\n",
    "################################\n",
    "# Check existing special tokens\n",
    "################################\n",
    "print(tokenizer, f\"\\n{'=' * 80}\\n\")"
   ],
   "id": "7eccbfc90c36577b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='../model/LORA_SFT/merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot', vocab_size=200019, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
      "\t199999: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200018: AddedToken(\"<|endofprompt|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200019: AddedToken(\"<|assistant|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200020: AddedToken(\"<|end|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200021: AddedToken(\"<|user|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200022: AddedToken(\"<|system|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t200023: AddedToken(\"<|tool|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200024: AddedToken(\"<|/tool|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200025: AddedToken(\"<|tool_call|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200026: AddedToken(\"<|/tool_call|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200027: AddedToken(\"<|tool_response|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200028: AddedToken(\"<|tag|>\", rstrip=True, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ") \n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# <font color='cornflowerblue'>Data processing</font>"
   ],
   "id": "dad2025ab2858bec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:45.564704Z",
     "start_time": "2025-11-06T10:24:45.450148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "processed_final_test_dataset = Dataset.load_from_disk(os.path.join(local_DEV_TEST_hf_dataset_dir, \"test\"))\n",
    "\n",
    "print(f\"\\n\\033[32m{len(processed_final_test_dataset)}\\033[0m\\n\")\n",
    "\n",
    "processed_final_test_dataset[4]"
   ],
   "id": "bef08d0562485838",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[32m1500\u001B[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ASQE_4',\n",
       " 'task_type': 'ASQE',\n",
       " 'entry_id': '4',\n",
       " 'original_id': '2_4496_234',\n",
       " 'input': 'Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.',\n",
       " 'prompt': '### Instruction:\\nGiven the input text, extract ALL pairs of opinion expressions and their corresponding aspect terms about the course, staff, or university. Then classify the category and sentiment for each aspect-opinion pair.\\nOpinion expressions are words/phrases expressing evaluation, feeling, or judgment (including both explicit and implicit opinions, not objective facts).\\nAspect terms are opinion targets. Only use a pronoun if you cannot find a direct aspect term in the same sentence or adjacent context. \\nEach aspect-opinion-category-sentiment combination is a quadruplet. \\n\\n**Rules:**\\n- Extract EVERY opinion in the text, including both explicit and implicit opinion expressions.\\n- Extract all opinion and aspect terms VERBATIM and as CONSECUTIVE tokens. \\n- Use \\'null\\' for implicit aspects. Opinions cannot be null.\\n- If an aspect is mapped to multiple opinion expressions, or vice versa, extract each 1:1 pair separately. \\n- Categorise each aspect-opinion pair first into one main category (the keys) in the category_mapping below, and then into one of its appropriate subcategories (values for the key). The category label follows \"Main category - subcategory\" format.\\ncategory_mapping = {\\n  \"Course\": [\"Content\", \"Learning activity\", \"Assessment\", \"Workload\", \"Difficulty\", \"Course materials\", \"Technology & tools\", \"Overall\"],\\n  \"Staff\": [\"Teaching\", \"Knowledge & skills\", \"Helpfulness\", \"Attitude\", \"Personal traits\", \"Overall\"],\\n  \"University\": [\"Cost\", \"Opportunities\", \"Programme\", \"Campus & facilities\", \"Culture & diversity\", \"Information & Services\", \"Social engagement & activities\", \"Overall\"]\\n}\\n\\n- Classify the sentiment into one of \\'positive\\', \\'neutral\\', \\'negative\\'. \\n- Use these specific tags for each component within each quadruplet: <asp>aspect terms</asp>, <opn>opinion expressions</opn>, <cat>category</cat>, <sen>sentiment</sen>\\n\\n**Critical formatting requirements:**\\n- Output MUST be a valid Python list\\n- Quadruplets MUST be separated by commas\\n\\n**Output format:** \\n[<asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>, <asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>, ..., <asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>]\\n\\n### Examples:\\nInput: \"The professor was knowledgeable but the assignments were too hard.\"\\nOutput: [<asp>professor</asp><opn>knowledgeable</opn><cat>Staff - Knowledge & skills</cat><sen>positive</sen>, <asp>assignments</asp><opn>too hard</opn><cat>Course - Assessment</cat><sen>negative</sen>]\\n\\nInput: \"It was disappointing overall.\"\\nOutput: [<asp>null</asp><opn>disappointing</opn><cat>Course - Overall</cat><sen>negative</sen>]\\n\\nInput: \"She never reply to emails or answer questions\"\\nOutput: [<asp>She</asp><opn>never reply to emails or answer questions</opn><cat>Staff - Helpfulness</cat><sen>negative</sen>]\\n\\nInput: \"There were 10 assignments, 5 quizzes, 1 final exam.\"\\nOutput: [<asp></asp><opn></opn><cat></cat><sen></sen>]\\n',\n",
       " 'entry_list': ['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn><cat>Course - Overall</cat><sen>negative</sen>',\n",
       "  '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat><sen>negative</sen>',\n",
       "  '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat><sen>negative</sen>',\n",
       "  '<asp>null</asp><opn>good mark booster</opn><cat>Course - Difficulty</cat><sen>positive</sen>',\n",
       "  '<asp>null</asp><opn>not particularly useful</opn><cat>Course - Overall</cat><sen>negative</sen>'],\n",
       " 'output': ['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn><cat>Course - Overall</cat><sen>negative</sen>',\n",
       "  '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat><sen>negative</sen>',\n",
       "  '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat><sen>negative</sen>',\n",
       "  '<asp>null</asp><opn>good mark booster</opn><cat>Course - Difficulty</cat><sen>positive</sen>',\n",
       "  '<asp>null</asp><opn>not particularly useful</opn><cat>Course - Overall</cat><sen>negative</sen>'],\n",
       " 'text': '### Task type: aspect-sentiment quadruplet extraction (ASQE)\\n### Instruction:\\nGiven the input text, extract ALL pairs of opinion expressions and their corresponding aspect terms about the course, staff, or university. Then classify the category and sentiment for each aspect-opinion pair.\\nOpinion expressions are words/phrases expressing evaluation, feeling, or judgment (including both explicit and implicit opinions, not objective facts).\\nAspect terms are opinion targets. Only use a pronoun if you cannot find a direct aspect term in the same sentence or adjacent context. \\nEach aspect-opinion-category-sentiment combination is a quadruplet. \\n\\n**Rules:**\\n- Extract EVERY opinion in the text, including both explicit and implicit opinion expressions.\\n- Extract all opinion and aspect terms VERBATIM and as CONSECUTIVE tokens. \\n- Use \\'null\\' for implicit aspects. Opinions cannot be null.\\n- If an aspect is mapped to multiple opinion expressions, or vice versa, extract each 1:1 pair separately. \\n- Categorise each aspect-opinion pair first into one main category (the keys) in the category_mapping below, and then into one of its appropriate subcategories (values for the key). The category label follows \"Main category - subcategory\" format.\\ncategory_mapping = {\\n  \"Course\": [\"Content\", \"Learning activity\", \"Assessment\", \"Workload\", \"Difficulty\", \"Course materials\", \"Technology & tools\", \"Overall\"],\\n  \"Staff\": [\"Teaching\", \"Knowledge & skills\", \"Helpfulness\", \"Attitude\", \"Personal traits\", \"Overall\"],\\n  \"University\": [\"Cost\", \"Opportunities\", \"Programme\", \"Campus & facilities\", \"Culture & diversity\", \"Information & Services\", \"Social engagement & activities\", \"Overall\"]\\n}\\n\\n- Classify the sentiment into one of \\'positive\\', \\'neutral\\', \\'negative\\'. \\n- Use these specific tags for each component within each quadruplet: <asp>aspect terms</asp>, <opn>opinion expressions</opn>, <cat>category</cat>, <sen>sentiment</sen>\\n\\n**Critical formatting requirements:**\\n- Output MUST be a valid Python list\\n- Quadruplets MUST be separated by commas\\n\\n**Output format:** \\n[<asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>, <asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>, ..., <asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>]\\n\\n### Examples:\\nInput: \"The professor was knowledgeable but the assignments were too hard.\"\\nOutput: [<asp>professor</asp><opn>knowledgeable</opn><cat>Staff - Knowledge & skills</cat><sen>positive</sen>, <asp>assignments</asp><opn>too hard</opn><cat>Course - Assessment</cat><sen>negative</sen>]\\n\\nInput: \"It was disappointing overall.\"\\nOutput: [<asp>null</asp><opn>disappointing</opn><cat>Course - Overall</cat><sen>negative</sen>]\\n\\nInput: \"She never reply to emails or answer questions\"\\nOutput: [<asp>She</asp><opn>never reply to emails or answer questions</opn><cat>Staff - Helpfulness</cat><sen>negative</sen>]\\n\\nInput: \"There were 10 assignments, 5 quizzes, 1 final exam.\"\\nOutput: [<asp></asp><opn></opn><cat></cat><sen></sen>]\\n\\n### Input:\\n```Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.```',\n",
       " 'type': 'course review'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:45.598304Z",
     "start_time": "2025-11-06T10:24:45.596048Z"
    }
   },
   "cell_type": "code",
   "source": "print(processed_final_test_dataset[4]['text'])",
   "id": "1970f134fa03a5c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task type: aspect-sentiment quadruplet extraction (ASQE)\n",
      "### Instruction:\n",
      "Given the input text, extract ALL pairs of opinion expressions and their corresponding aspect terms about the course, staff, or university. Then classify the category and sentiment for each aspect-opinion pair.\n",
      "Opinion expressions are words/phrases expressing evaluation, feeling, or judgment (including both explicit and implicit opinions, not objective facts).\n",
      "Aspect terms are opinion targets. Only use a pronoun if you cannot find a direct aspect term in the same sentence or adjacent context. \n",
      "Each aspect-opinion-category-sentiment combination is a quadruplet. \n",
      "\n",
      "**Rules:**\n",
      "- Extract EVERY opinion in the text, including both explicit and implicit opinion expressions.\n",
      "- Extract all opinion and aspect terms VERBATIM and as CONSECUTIVE tokens. \n",
      "- Use 'null' for implicit aspects. Opinions cannot be null.\n",
      "- If an aspect is mapped to multiple opinion expressions, or vice versa, extract each 1:1 pair separately. \n",
      "- Categorise each aspect-opinion pair first into one main category (the keys) in the category_mapping below, and then into one of its appropriate subcategories (values for the key). The category label follows \"Main category - subcategory\" format.\n",
      "category_mapping = {\n",
      "  \"Course\": [\"Content\", \"Learning activity\", \"Assessment\", \"Workload\", \"Difficulty\", \"Course materials\", \"Technology & tools\", \"Overall\"],\n",
      "  \"Staff\": [\"Teaching\", \"Knowledge & skills\", \"Helpfulness\", \"Attitude\", \"Personal traits\", \"Overall\"],\n",
      "  \"University\": [\"Cost\", \"Opportunities\", \"Programme\", \"Campus & facilities\", \"Culture & diversity\", \"Information & Services\", \"Social engagement & activities\", \"Overall\"]\n",
      "}\n",
      "\n",
      "- Classify the sentiment into one of 'positive', 'neutral', 'negative'. \n",
      "- Use these specific tags for each component within each quadruplet: <asp>aspect terms</asp>, <opn>opinion expressions</opn>, <cat>category</cat>, <sen>sentiment</sen>\n",
      "\n",
      "**Critical formatting requirements:**\n",
      "- Output MUST be a valid Python list\n",
      "- Quadruplets MUST be separated by commas\n",
      "\n",
      "**Output format:** \n",
      "[<asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>, <asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>, ..., <asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>]\n",
      "\n",
      "### Examples:\n",
      "Input: \"The professor was knowledgeable but the assignments were too hard.\"\n",
      "Output: [<asp>professor</asp><opn>knowledgeable</opn><cat>Staff - Knowledge & skills</cat><sen>positive</sen>, <asp>assignments</asp><opn>too hard</opn><cat>Course - Assessment</cat><sen>negative</sen>]\n",
      "\n",
      "Input: \"It was disappointing overall.\"\n",
      "Output: [<asp>null</asp><opn>disappointing</opn><cat>Course - Overall</cat><sen>negative</sen>]\n",
      "\n",
      "Input: \"She never reply to emails or answer questions\"\n",
      "Output: [<asp>She</asp><opn>never reply to emails or answer questions</opn><cat>Staff - Helpfulness</cat><sen>negative</sen>]\n",
      "\n",
      "Input: \"There were 10 assignments, 5 quizzes, 1 final exam.\"\n",
      "Output: [<asp></asp><opn></opn><cat></cat><sen></sen>]\n",
      "\n",
      "### Input:\n",
      "```Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.```\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:45.652060Z",
     "start_time": "2025-11-06T10:24:45.648554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"\\n\\033[36m{processed_final_test_dataset.unique('task_type')}\\033[0m\\n\")\n",
    "processed_final_test_dataset"
   ],
   "id": "2d34b5f1208744d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[36m['OE', 'AOPE', 'AOC', 'ASTE', 'ASQE']\u001B[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'task_type', 'entry_id', 'original_id', 'input', 'prompt', 'entry_list', 'output', 'text', 'type'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## <font color='magenta'>Make a small subset for testing</font>",
   "id": "f4ecccdc941e46d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:45.725284Z",
     "start_time": "2025-11-06T10:24:45.721351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if try_small_sample_with_this_script:\n",
    "\n",
    "    processed_final_test_dataset = processed_final_test_dataset.select(range(20))\n",
    "    \n",
    "    print(f\"\\033[1;30;45mTrimmed dataset for testing, total entries = {len(processed_final_test_dataset)}\\033[0m\\n\")\n",
    "else:\n",
    "    print(f\"\\033[1;30;42mUse full test set of {len(processed_final_test_dataset)} entries. \\033[0m\\n\")\n",
    "    \n",
    "processed_final_test_dataset"
   ],
   "id": "2bb784ed5cadc272",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;30;45mTrimmed dataset for testing, total entries = 20\u001B[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'task_type', 'entry_id', 'original_id', 'input', 'prompt', 'entry_list', 'output', 'text', 'type'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# <font color='gold'>Evaluate merged model</font>"
   ],
   "id": "4867cc53ce1d95fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:47.385504Z",
     "start_time": "2025-11-06T10:24:45.830030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################################\n",
    "# Load pre-trained model & set up trainer\n",
    "###############################################\n",
    "\n",
    "tokenizer.padding_side = 'left'  # left for generation, right for training\n",
    "\n",
    "merged_model = AutoModelForCausalLM.from_pretrained(model_checkpoint_path, **evaluation_model_kwargs)\n",
    "\n",
    "print(f\"\\n\\033[33meval model kwargs:\\033[0m\\n{evaluation_model_kwargs}\\n\")\n",
    "print(f\"\\033[33mTokenizer padding:\\033[0m  {tokenizer.pad_token}, {tokenizer.padding_side}\")\n",
    "\n",
    "# if config specifies, move model to GPU \n",
    "# if evaluation_model_to_gpu: \n",
    "merged_model = merged_model.to(device) \n",
    "print(f\"\\033[35m\\n{'*'*20}\\nmoving merged_model to {device}\\n{'*'*20}\\n\\033[0m\")\n",
    "    \n",
    "print_gpu_utilization()\n",
    "    \n",
    "print(f\"Evaluating pre-trained model on test dataset\")"
   ],
   "id": "49cc71c93ddc308d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c40a38ec5608479ebc1d7c29b17fc133"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[33meval model kwargs:\u001B[0m\n",
      "{'use_cache': False, 'trust_remote_code': False, 'attn_implementation': 'flash_attention_2', 'torch_dtype': torch.bfloat16, 'device_map': {'': 0}}\n",
      "\n",
      "\u001B[33mTokenizer padding:\u001B[0m  <|endoftext|>, left\n",
      "\u001B[35m\n",
      "********************\n",
      "moving merged_model to cuda\n",
      "********************\n",
      "\u001B[0m\n",
      "\u001B[35mGPU memory occupied: 8662 MB\u001B[0m\n",
      "\n",
      "Evaluating pre-trained model on test dataset\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:24:47.401035Z",
     "start_time": "2025-11-06T10:24:47.398784Z"
    }
   },
   "cell_type": "code",
   "source": "generation_args",
   "id": "cfdfa356b8a699e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_new_tokens': 1024,\n",
       " 'return_full_text': False,\n",
       " 'temperature': None,\n",
       " 'top_p': None,\n",
       " 'top_k': None,\n",
       " 'do_sample': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.185982Z",
     "start_time": "2025-11-06T10:24:47.564949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "###############################################\n",
    "# Evaluate fine-tuned model on ABSA tasks\n",
    "###############################################\n",
    "\n",
    "inference_pipeline = pipeline(\"text-generation\", model=merged_model, tokenizer=tokenizer, torch_dtype=evaluation_model_kwargs['torch_dtype']) \n",
    "\n",
    "model_output = evaluator.evaluate_model(pipeline=inference_pipeline,\n",
    "                                        generation_args=generation_args,\n",
    "                                        test_dataset=processed_final_test_dataset,\n",
    "                                        view_result=evaluation_setting['eval_setting_view_sample'],\n",
    "                                        view_size=evaluation_setting['eval_setting_view_size'],\n",
    "                                        handle_format_error = evaluation_setting['handle_format_error'],\n",
    "                                        show_table=evaluation_setting['eval_setting_show_table'],\n",
    "                                        return_input_dict=True,\n",
    "                                        show_first_5_messages=True\n",
    "                                        )"
   ],
   "id": "78be9cff66c43965",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49bd0fc9944c4d26986d5e554492d0e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m0 (OE): \u001B[0m [{'role': 'system', 'content': 'You are an expert in aspect-based sentiment analysis.'}, {'role': 'user', 'content': '### Task type: opinion extraction (OE)\\n### Instruction: \\nGiven the input text, extract ALL opinion expressions about the course, staff, or university. \\nOpinion expressions are words/phrases expressing evaluation, feeling, or judgment (including both explicit and implicit opinions, not objective facts).\\n\\n**Rules:**\\n- Extract each opinion expression VERBATIM and as CONSECUTIVE tokens.\\n- Extract EVERY opinion in the text, including both explicit and implicit opinion expressions.\\n- Use these specific tags for each extracted opinion expression: <opn>opinion expressions</opn>\\n\\n**Critical formatting requirements:**\\n- Output MUST be a valid Python list\\n- Tag-wrapped units MUST be separated by commas\\n\\n**Output format:** \\n[<opn>...</opn>, <opn>...</opn>, ..., <opn>...</opn>]\\n\\n### Examples:\\nInput: \"The professor was knowledgeable but the assignments were too hard.\"\\nOutput: [<opn>knowledgeable</opn>, <opn>too hard</opn>]\\n\\nInput: \"I strongly recommend it.\"\\nOutput: [<opn>strongly recommend</opn>]\\n\\nInput: \"She never reply to emails or answer questions\"\\nOutput: [<opn>never reply to emails or answer questions</opn>]\\n\\nInput: \"There were 10 assignments, 5 quizzes, 1 final exam.\"\\nOutput: [<opn></opn>]\\n\\n### Input:\\n```Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.```'}]\n",
      "0. \u001B[1;30;44m    OE    \u001B[0m\n",
      "Input:\n",
      "\u001B[33mStudied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<opn>Not as interesting as I thought it would be tho</opn>', '<opn>dry</opn>', '<opn>put me to sleep</opn>', '<opn>good mark booster</opn>', '<opn>not particularly useful</opn>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<opn>good mark booster</opn>, <opn>not particularly useful</opn>, <opn>Not as interesting as I thought it would be</opn>, <opn>dry</opn>, <opn>put me to sleep</opn>, <opn>good mark booster</opn>, <opn>not particularly useful</opn>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<opn>good mark booster</opn>', '<opn>not particularly useful</opn>', '<opn>Not as interesting as I thought it would be</opn>', '<opn>dry</opn>', '<opn>put me to sleep</opn>', '<opn>good mark booster</opn>', '<opn>not particularly useful</opn>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "\u001B[36m1 (AOPE): \u001B[0m [{'role': 'system', 'content': 'You are an expert in aspect-based sentiment analysis.'}, {'role': 'user', 'content': '### Task type: aspect-opinion pair extraction (AOPE)\\n### Instruction:\\nGiven the input text, extract ALL pairs of opinion expressions and their corresponding aspect terms about the course, staff, or university.\\nOpinion expressions are words/phrases expressing evaluation, feeling, or judgment (including both explicit and implicit opinions, not objective facts).\\nAspect terms are opinion targets. Only use a pronoun if you cannot find a direct aspect term in the same sentence or adjacent context. \\nEach aspect-opinion combination is a pair. \\n\\n**Rules:**\\n- Extract EVERY opinion in the text, including both explicit and implicit opinion expressions.\\n- Extract all opinion and aspect terms VERBATIM and as CONSECUTIVE tokens. \\n- Use \\'null\\' for implicit aspects. Opinions cannot be null.\\n- If an aspect is mapped to multiple opinion expressions, or vice versa, extract each 1:1 pair separately. \\n- Use these specific tags for each component within each pair: <asp>aspect terms</asp>, <opn>opinion expressions</opn>\\n\\n**Critical formatting requirements:**\\n- Output MUST be a valid Python list\\n- Pairs MUST be separated by commas\\n\\n**Output format:** \\n[<asp>...</asp><opn>...</opn>, <asp>...</asp><opn>...</opn>, ..., <asp>...</asp><opn>...</opn>]\\n\\n### Examples:\\nInput: \"The professor was knowledgeable but the assignments were too hard.\"\\nOutput: [<asp>professor</asp><opn>knowledgeable</opn>, <asp>assignments</asp><opn>too hard</opn>]\\n\\nInput: \"I strongly recommend it.\"\\nOutput: [<asp>null</asp><opn>strongly recommend</opn>]\\n\\nInput: \"She never reply to emails or answer questions\"\\nOutput: [<asp>She</asp><opn>never reply to emails or answer questions</opn>]\\n\\nInput: \"There were 10 assignments, 5 quizzes, 1 final exam.\"\\nOutput: [<asp></asp><opn></opn>]\\n\\n### Input:\\n```Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.```'}]\n",
      "1. \u001B[1;30;44m   AOPE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mStudied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn>', '<asp>textbook</asp><opn>dry</opn>', '<asp>lectures</asp><opn>put me to sleep</opn>', '<asp>null</asp><opn>good mark booster</opn>', '<asp>null</asp><opn>not particularly useful</opn>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>null</asp><opn>not as interesting as I thought it would be</opn>, <asp>textbook</asp><opn>dry</opn>, <asp>lectures</asp><opn>put me to sleep</opn>, <asp>null</asp><opn>good mark booster</opn>, <asp>null</asp><opn>not particularly useful</opn>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>null</asp><opn>not as interesting as I thought it would be</opn>', '<asp>textbook</asp><opn>dry</opn>', '<asp>lectures</asp><opn>put me to sleep</opn>', '<asp>null</asp><opn>good mark booster</opn>', '<asp>null</asp><opn>not particularly useful</opn>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "\u001B[36m2 (AOC): \u001B[0m [{'role': 'system', 'content': 'You are an expert in aspect-based sentiment analysis.'}, {'role': 'user', 'content': '### Task type: aspect-opinion classification (AOC)\\n### Instruction:\\nGiven the input text, extract ALL pairs of opinion expressions and their corresponding aspect terms about the course, staff, or university. Then classify the category for each aspect-opinion pair.\\nOpinion expressions are words/phrases expressing evaluation, feeling, or judgment (including both explicit and implicit opinions, not objective facts).\\nAspect terms are opinion targets. Only use a pronoun if you cannot find a direct aspect term in the same sentence or adjacent context. \\nEach aspect-opinion-category combination is a triplet. \\n\\n**Rules:**\\n- Extract EVERY opinion in the text, including both explicit and implicit opinion expressions.\\n- Extract all opinion and aspect terms VERBATIM and as CONSECUTIVE tokens. \\n- Use \\'null\\' for implicit aspects. Opinions cannot be null.\\n- If an aspect is mapped to multiple opinion expressions, or vice versa, extract each 1:1 pair separately. \\n- Categorise each aspect-opinion pair first into one main category (the keys) in the category_mapping below, and then into one of its appropriate subcategories (values for the key). The category label follows \"Main category - subcategory\" format.\\ncategory_mapping = {\\n  \"Course\": [\"Content\", \"Learning activity\", \"Assessment\", \"Workload\", \"Difficulty\", \"Course materials\", \"Technology & tools\", \"Overall\"],\\n  \"Staff\": [\"Teaching\", \"Knowledge & skills\", \"Helpfulness\", \"Attitude\", \"Personal traits\", \"Overall\"],\\n  \"University\": [\"Cost\", \"Opportunities\", \"Programme\", \"Campus & facilities\", \"Culture & diversity\", \"Information & Services\", \"Social engagement & activities\", \"Overall\"]\\n}\\n\\n- Use these specific tags for each component within each triplet: <asp>aspect terms</asp>, <opn>opinion expressions</opn>, <cat>category</cat>\\n\\n**Critical formatting requirements:**\\n- Output MUST be a valid Python list\\n- Triplets MUST be separated by commas\\n\\n**Output format:** \\n[<asp>...</asp><opn>...</opn><cat>...</cat>, <asp>...</asp><opn>...</opn><cat>...</cat>, ..., <asp>...</asp><opn>...</opn><cat>...</cat>]\\n\\n### Examples:\\nInput: \"The professor was knowledgeable but the assignments were too hard.\"\\nOutput: [<asp>professor</asp><opn>knowledgeable</opn><cat>Staff - Knowledge & skills</cat>, <asp>assignments</asp><opn>too hard</opn><cat>Course - Assessment</cat>]\\n\\nInput: \"It was disappointing overall.\"\\nOutput: [<asp>null</asp><opn>disappointing</opn><cat>Course - Overall</cat>]\\n\\nInput: \"She never reply to emails or answer questions\"\\nOutput: [<asp>She</asp><opn>never reply to emails or answer questions</opn><cat>Staff - Helpfulness</cat>]\\n\\nInput: \"There were 10 assignments, 5 quizzes, 1 final exam.\"\\nOutput: [<asp></asp><opn></opn><cat></cat>]\\n\\n### Input:\\n```Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.```'}]\n",
      "2. \u001B[1;30;44m   AOC    \u001B[0m\n",
      "Input:\n",
      "\u001B[33mStudied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn><cat>Course - Overall</cat>', '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat>', '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat>', '<asp>null</asp><opn>good mark booster</opn><cat>Course - Difficulty</cat>', '<asp>null</asp><opn>not particularly useful</opn><cat>Course - Overall</cat>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>exam</asp><opn>literally the day of</opn><cat>Course - Assessment</cat>, <asp>exam</asp><opn>90%</opn><cat>Course - Assessment</cat>, <asp>exam</asp><opn>Not as interesting as I thought it would be</opn><cat>Course - Overall</cat>, <asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat>, <asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat>, <asp>course</asp><opn>good mark booster</opn><cat>Course - Overall</cat>, <asp>course</asp><opn>not particularly useful</opn><cat>Course - Overall</cat>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>exam</asp><opn>literally the day of</opn><cat>Course - Assessment</cat>', '<asp>exam</asp><opn>90%</opn><cat>Course - Assessment</cat>', '<asp>exam</asp><opn>Not as interesting as I thought it would be</opn><cat>Course - Overall</cat>', '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat>', '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat>', '<asp>course</asp><opn>good mark booster</opn><cat>Course - Overall</cat>', '<asp>course</asp><opn>not particularly useful</opn><cat>Course - Overall</cat>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "\u001B[36m3 (ASTE): \u001B[0m [{'role': 'system', 'content': 'You are an expert in aspect-based sentiment analysis.'}, {'role': 'user', 'content': '### Task type: aspect-sentiment triplet extraction (ASTE)\\n### Instruction:\\nGiven the input text, extract ALL pairs of opinion expressions and their corresponding aspect terms about the course, staff, or university. Then classify the sentiment for each aspect-opinion pair.\\nOpinion expressions are words/phrases expressing evaluation, feeling, or judgment (including both explicit and implicit opinions, not objective facts).\\nAspect terms are opinion targets. Only use a pronoun if you cannot find a direct aspect term in the same sentence or adjacent context. \\nEach aspect-opinion-sentiment combination is a triplet. \\n\\n**Rules:**\\n- Extract EVERY opinion in the text, including both explicit and implicit opinion expressions.\\n- Extract all opinion and aspect terms VERBATIM and as CONSECUTIVE tokens. \\n- Use \\'null\\' for implicit aspects. Opinions cannot be null.\\n- If an aspect is mapped to multiple opinion expressions, or vice versa, extract each 1:1 pair separately. \\n- Classify the sentiment into one of \\'positive\\', \\'neutral\\', \\'negative\\'. \\n- Use these specific tags for each component within each triplet: <asp>aspect terms</asp>, <opn>opinion expressions</opn>, <sen>sentiment</sen>\\n\\n**Critical formatting requirements:**\\n- Output MUST be a valid Python list\\n- Triplets MUST be separated by commas\\n\\n**Output format:** \\n[<asp>...</asp><opn>...</opn><sen>...</sen>, <asp>...</asp><opn>...</opn><sen>...</sen>, ..., <asp>...</asp><opn>...</opn><sen>...</sen>]\\n\\n### Examples:\\nInput: \"The professor was knowledgeable but the assignments were too hard.\"\\nOutput: [<asp>professor</asp><opn>knowledgeable</opn><sen>positive</sen>, <asp>assignments</asp><opn>too hard</opn><sen>negative</sen>]\\n\\nInput: \"It was disappointing overall.\"\\nOutput: [<asp>null</asp><opn>disappointing</opn><sen>negative</sen>]\\n\\nInput: \"She never reply to emails or answer questions\"\\nOutput: [<asp>She</asp><opn>never reply to emails or answer questions</opn><sen>negative</sen>]\\n\\nInput: \"There were 10 assignments, 5 quizzes, 1 final exam.\"\\nOutput: [<asp></asp><opn></opn><sen></sen>]\\n\\n### Input:\\n```Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.```'}]\n",
      "3. \u001B[1;30;44m   ASTE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mStudied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn><sen>negative</sen>', '<asp>textbook</asp><opn>dry</opn><sen>negative</sen>', '<asp>lectures</asp><opn>put me to sleep</opn><sen>negative</sen>', '<asp>null</asp><opn>good mark booster</opn><sen>positive</sen>', '<asp>null</asp><opn>not particularly useful</opn><sen>negative</sen>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>null</asp><opn>not as interesting as I thought it would be</opn><sen>negative</sen>, <asp>textbook</asp><opn>dry</opn><sen>negative</sen>, <asp>lectures</asp><opn>put me to sleep</opn><sen>negative</sen>, <asp>null</asp><opn>good mark booster</opn><sen>positive</sen>, <asp>null</asp><opn>not particularly useful</opn><sen>negative</sen>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>null</asp><opn>not as interesting as I thought it would be</opn><sen>negative</sen>', '<asp>textbook</asp><opn>dry</opn><sen>negative</sen>', '<asp>lectures</asp><opn>put me to sleep</opn><sen>negative</sen>', '<asp>null</asp><opn>good mark booster</opn><sen>positive</sen>', '<asp>null</asp><opn>not particularly useful</opn><sen>negative</sen>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "\u001B[36m4 (ASQE): \u001B[0m [{'role': 'system', 'content': 'You are an expert in aspect-based sentiment analysis.'}, {'role': 'user', 'content': '### Task type: aspect-sentiment quadruplet extraction (ASQE)\\n### Instruction:\\nGiven the input text, extract ALL pairs of opinion expressions and their corresponding aspect terms about the course, staff, or university. Then classify the category and sentiment for each aspect-opinion pair.\\nOpinion expressions are words/phrases expressing evaluation, feeling, or judgment (including both explicit and implicit opinions, not objective facts).\\nAspect terms are opinion targets. Only use a pronoun if you cannot find a direct aspect term in the same sentence or adjacent context. \\nEach aspect-opinion-category-sentiment combination is a quadruplet. \\n\\n**Rules:**\\n- Extract EVERY opinion in the text, including both explicit and implicit opinion expressions.\\n- Extract all opinion and aspect terms VERBATIM and as CONSECUTIVE tokens. \\n- Use \\'null\\' for implicit aspects. Opinions cannot be null.\\n- If an aspect is mapped to multiple opinion expressions, or vice versa, extract each 1:1 pair separately. \\n- Categorise each aspect-opinion pair first into one main category (the keys) in the category_mapping below, and then into one of its appropriate subcategories (values for the key). The category label follows \"Main category - subcategory\" format.\\ncategory_mapping = {\\n  \"Course\": [\"Content\", \"Learning activity\", \"Assessment\", \"Workload\", \"Difficulty\", \"Course materials\", \"Technology & tools\", \"Overall\"],\\n  \"Staff\": [\"Teaching\", \"Knowledge & skills\", \"Helpfulness\", \"Attitude\", \"Personal traits\", \"Overall\"],\\n  \"University\": [\"Cost\", \"Opportunities\", \"Programme\", \"Campus & facilities\", \"Culture & diversity\", \"Information & Services\", \"Social engagement & activities\", \"Overall\"]\\n}\\n\\n- Classify the sentiment into one of \\'positive\\', \\'neutral\\', \\'negative\\'. \\n- Use these specific tags for each component within each quadruplet: <asp>aspect terms</asp>, <opn>opinion expressions</opn>, <cat>category</cat>, <sen>sentiment</sen>\\n\\n**Critical formatting requirements:**\\n- Output MUST be a valid Python list\\n- Quadruplets MUST be separated by commas\\n\\n**Output format:** \\n[<asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>, <asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>, ..., <asp>...</asp><opn>...</opn><cat>...</cat><sen>...</sen>]\\n\\n### Examples:\\nInput: \"The professor was knowledgeable but the assignments were too hard.\"\\nOutput: [<asp>professor</asp><opn>knowledgeable</opn><cat>Staff - Knowledge & skills</cat><sen>positive</sen>, <asp>assignments</asp><opn>too hard</opn><cat>Course - Assessment</cat><sen>negative</sen>]\\n\\nInput: \"It was disappointing overall.\"\\nOutput: [<asp>null</asp><opn>disappointing</opn><cat>Course - Overall</cat><sen>negative</sen>]\\n\\nInput: \"She never reply to emails or answer questions\"\\nOutput: [<asp>She</asp><opn>never reply to emails or answer questions</opn><cat>Staff - Helpfulness</cat><sen>negative</sen>]\\n\\nInput: \"There were 10 assignments, 5 quizzes, 1 final exam.\"\\nOutput: [<asp></asp><opn></opn><cat></cat><sen></sen>]\\n\\n### Input:\\n```Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.```'}]\n",
      "4. \u001B[1;30;44m   ASQE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mStudied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn><cat>Course - Overall</cat><sen>negative</sen>', '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat><sen>negative</sen>', '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat><sen>negative</sen>', '<asp>null</asp><opn>good mark booster</opn><cat>Course - Difficulty</cat><sen>positive</sen>', '<asp>null</asp><opn>not particularly useful</opn><cat>Course - Overall</cat><sen>negative</sen>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>exam</asp><opn>literally the day of</opn><cat>Course - Assessment</cat><sen>neutral</sen>, <asp>exam</asp><opn>90%</opn><cat>Course - Assessment</cat><sen>positive</sen>, <asp>exam</asp><opn>Not as interesting as I thought it would be</opn><cat>Course - Overall</cat><sen>negative</sen>, <asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat><sen>negative</sen>, <asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat><sen>negative</sen>, <asp>course</asp><opn>good mark booster</opn><cat>Course - Overall</cat><sen>positive</sen>, <asp>course</asp><opn>not particularly useful</opn><cat>Course - Overall</cat><sen>negative</sen>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>exam</asp><opn>literally the day of</opn><cat>Course - Assessment</cat><sen>neutral</sen>', '<asp>exam</asp><opn>90%</opn><cat>Course - Assessment</cat><sen>positive</sen>', '<asp>exam</asp><opn>Not as interesting as I thought it would be</opn><cat>Course - Overall</cat><sen>negative</sen>', '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat><sen>negative</sen>', '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat><sen>negative</sen>', '<asp>course</asp><opn>good mark booster</opn><cat>Course - Overall</cat><sen>positive</sen>', '<asp>course</asp><opn>not particularly useful</opn><cat>Course - Overall</cat><sen>negative</sen>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "5. \u001B[1;30;44m    OE    \u001B[0m\n",
      "Input:\n",
      "\u001B[33mThe campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<opn>a beautiful place to work</opn>', '<opn>very green</opn>', '<opn>outstanding</opn>', '<opn>clearly striving for the best in every student</opn>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<opn>very green</opn>, <opn>beautiful</opn>, <opn>outstanding</opn>, <opn>striving for the best in every student</opn>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<opn>very green</opn>', '<opn>beautiful</opn>', '<opn>outstanding</opn>', '<opn>striving for the best in every student</opn>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "6. \u001B[1;30;44m   AOPE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mThe campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>campus</asp><opn>a beautiful place to work</opn>', '<asp>campus</asp><opn>very green</opn>', '<asp>facilities</asp><opn>outstanding</opn>', '<asp>staff</asp><opn>clearly striving for the best in every student</opn>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>campus</asp><opn>very green</opn>, <asp>campus</asp><opn>beautiful place to work</opn>, <asp>facilities</asp><opn>outstanding</opn>, <asp>staff</asp><opn>striving for the best in every student</opn>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>campus</asp><opn>very green</opn>', '<asp>campus</asp><opn>beautiful place to work</opn>', '<asp>facilities</asp><opn>outstanding</opn>', '<asp>staff</asp><opn>striving for the best in every student</opn>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "7. \u001B[1;30;44m   AOC    \u001B[0m\n",
      "Input:\n",
      "\u001B[33mThe campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>campus</asp><opn>a beautiful place to work</opn><cat>University - Campus & facilities</cat>', '<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat>', '<asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat>', '<asp>staff</asp><opn>clearly striving for the best in every student</opn><cat>Staff - Overall</cat>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat>, <asp>campus</asp><opn>beautiful place to work</opn><cat>University - Overall</cat>, <asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat>, <asp>staff</asp><opn>striving for the best in every student</opn><cat>Staff - Overall</cat>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat>', '<asp>campus</asp><opn>beautiful place to work</opn><cat>University - Overall</cat>', '<asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat>', '<asp>staff</asp><opn>striving for the best in every student</opn><cat>Staff - Overall</cat>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "8. \u001B[1;30;44m   ASTE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mThe campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>campus</asp><opn>a beautiful place to work</opn><sen>positive</sen>', '<asp>campus</asp><opn>very green</opn><sen>positive</sen>', '<asp>facilities</asp><opn>outstanding</opn><sen>positive</sen>', '<asp>staff</asp><opn>clearly striving for the best in every student</opn><sen>positive</sen>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>campus</asp><opn>very green</opn><sen>positive</sen>, <asp>campus</asp><opn>beautiful place to work</opn><sen>positive</sen>, <asp>facilities</asp><opn>outstanding</opn><sen>positive</sen>, <asp>staff</asp><opn>striving for the best in every student</opn><sen>positive</sen>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>campus</asp><opn>very green</opn><sen>positive</sen>', '<asp>campus</asp><opn>beautiful place to work</opn><sen>positive</sen>', '<asp>facilities</asp><opn>outstanding</opn><sen>positive</sen>', '<asp>staff</asp><opn>striving for the best in every student</opn><sen>positive</sen>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9. \u001B[1;30;44m   ASQE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mThe campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>campus</asp><opn>a beautiful place to work</opn><cat>University - Campus & facilities</cat><sen>positive</sen>', '<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat><sen>positive</sen>', '<asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat><sen>positive</sen>', '<asp>staff</asp><opn>clearly striving for the best in every student</opn><cat>Staff - Overall</cat><sen>positive</sen>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat><sen>positive</sen>, <asp>campus</asp><opn>beautiful place to work</opn><cat>University - Campus & facilities</cat><sen>positive</sen>, <asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat><sen>positive</sen>, <asp>staff</asp><opn>striving for the best in every student</opn><cat>Staff - Overall</cat><sen>positive</sen>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat><sen>positive</sen>', '<asp>campus</asp><opn>beautiful place to work</opn><cat>University - Campus & facilities</cat><sen>positive</sen>', '<asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat><sen>positive</sen>', '<asp>staff</asp><opn>striving for the best in every student</opn><cat>Staff - Overall</cat><sen>positive</sen>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "10. \u001B[1;30;44m    OE    \u001B[0m\n",
      "Input:\n",
      "\u001B[33mBad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<opn>Bad</opn>', '<opn>confused</opn>', '<opn>random</opn>', '<opn>disorganized</opn>', '<opn>hardly any explanation of concepts</opn>', \"<opn>You'll learn almost nothing</opn>\", '<opn>Not recommended</opn>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<opn>Bad</opn>, <opn>random</opn>, <opn>disorganized</opn>, <opn>hardly any explanation of concepts</opn>, <opn>confused</opn>, <opn>You\\'ll learn almost nothing</opn>, <opn>Not recommended</opn>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<opn>Bad</opn>', '<opn>random</opn>', '<opn>disorganized</opn>', '<opn>hardly any explanation of concepts</opn>', '<opn>confused</opn>', \"<opn>You'll learn almost nothing</opn>\", '<opn>Not recommended</opn>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "11. \u001B[1;30;44m   AOPE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mBad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>teaching</asp><opn>Bad</opn>', '<asp>teaching</asp><opn>confused</opn>', '<asp>teaching</asp><opn>random</opn>', '<asp>teaching</asp><opn>disorganized</opn>', '<asp>teaching</asp><opn>hardly any explanation of concepts</opn>', \"<asp>this course</asp><opn>You'll learn almost nothing</opn>\", '<asp>this course</asp><opn>Not recommended</opn>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>teaching</asp><opn>Bad</opn>, <asp>teaching</asp><opn>random</opn>, <asp>teaching</asp><opn>disorganized</opn>, <asp>explanation of concepts</asp><opn>hardly any</opn>, <asp>concepts</asp><opn>confused</opn>, <asp>this course</asp><opn>You\\'ll learn almost nothing</opn>, <asp>this course</asp><opn>Not recommended</opn>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>teaching</asp><opn>Bad</opn>', '<asp>teaching</asp><opn>random</opn>', '<asp>teaching</asp><opn>disorganized</opn>', '<asp>explanation of concepts</asp><opn>hardly any</opn>', '<asp>concepts</asp><opn>confused</opn>', \"<asp>this course</asp><opn>You'll learn almost nothing</opn>\", '<asp>this course</asp><opn>Not recommended</opn>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "12. \u001B[1;30;44m   AOC    \u001B[0m\n",
      "Input:\n",
      "\u001B[33mBad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat>', '<asp>teaching</asp><opn>confused</opn><cat>Staff - Teaching</cat>', '<asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat>', '<asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat>', '<asp>teaching</asp><opn>hardly any explanation of concepts</opn><cat>Staff - Teaching</cat>', \"<asp>this course</asp><opn>You'll learn almost nothing</opn><cat>Course - Overall</cat>\", '<asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat>, <asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat>, <asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat>, <asp>explanation of concepts</asp><opn>hardly any</opn><cat>Staff - Teaching</cat>, <asp>concepts</asp><opn>confused</opn><cat>Staff - Teaching</cat>, <asp>this course</asp><opn>You\\'ll learn almost nothing</opn><cat>Course - Overall</cat>, <asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat>', '<asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat>', '<asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat>', '<asp>explanation of concepts</asp><opn>hardly any</opn><cat>Staff - Teaching</cat>', '<asp>concepts</asp><opn>confused</opn><cat>Staff - Teaching</cat>', \"<asp>this course</asp><opn>You'll learn almost nothing</opn><cat>Course - Overall</cat>\", '<asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "13. \u001B[1;30;44m   ASTE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mBad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>teaching</asp><opn>Bad</opn><sen>negative</sen>', '<asp>teaching</asp><opn>confused</opn><sen>negative</sen>', '<asp>teaching</asp><opn>random</opn><sen>negative</sen>', '<asp>teaching</asp><opn>disorganized</opn><sen>negative</sen>', '<asp>teaching</asp><opn>hardly any explanation of concepts</opn><sen>negative</sen>', \"<asp>this course</asp><opn>You'll learn almost nothing</opn><sen>negative</sen>\", '<asp>this course</asp><opn>Not recommended</opn><sen>negative</sen>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>teaching</asp><opn>Bad</opn><sen>negative</sen>, <asp>teaching</asp><opn>random</opn><sen>negative</sen>, <asp>teaching</asp><opn>disorganized</opn><sen>negative</sen>, <asp>explanation of concepts</asp><opn>hardly any</opn><sen>negative</sen>, <asp>concepts</asp><opn>confused</opn><sen>negative</sen>, <asp>this course</asp><opn>You\\'ll learn almost nothing</opn><sen>negative</sen>, <asp>this course</asp><opn>Not recommended</opn><sen>negative</sen>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>teaching</asp><opn>Bad</opn><sen>negative</sen>', '<asp>teaching</asp><opn>random</opn><sen>negative</sen>', '<asp>teaching</asp><opn>disorganized</opn><sen>negative</sen>', '<asp>explanation of concepts</asp><opn>hardly any</opn><sen>negative</sen>', '<asp>concepts</asp><opn>confused</opn><sen>negative</sen>', \"<asp>this course</asp><opn>You'll learn almost nothing</opn><sen>negative</sen>\", '<asp>this course</asp><opn>Not recommended</opn><sen>negative</sen>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "14. \u001B[1;30;44m   ASQE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mBad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat><sen>negative</sen>', '<asp>teaching</asp><opn>confused</opn><cat>Staff - Teaching</cat><sen>negative</sen>', '<asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat><sen>negative</sen>', '<asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat><sen>negative</sen>', '<asp>teaching</asp><opn>hardly any explanation of concepts</opn><cat>Staff - Teaching</cat><sen>negative</sen>', \"<asp>this course</asp><opn>You'll learn almost nothing</opn><cat>Course - Overall</cat><sen>negative</sen>\", '<asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat><sen>negative</sen>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat><sen>negative</sen>, <asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat><sen>negative</sen>, <asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat><sen>negative</sen>, <asp>explanation of concepts</asp><opn>hardly any</opn><cat>Staff - Teaching</cat><sen>negative</sen>, <asp>concepts</asp><opn>confused</opn><cat>Staff - Teaching</cat><sen>negative</sen>, <asp>this course</asp><opn>You\\'ll learn almost nothing</opn><cat>Course - Overall</cat><sen>negative</sen>, <asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat><sen>negative</sen>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat><sen>negative</sen>', '<asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat><sen>negative</sen>', '<asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat><sen>negative</sen>', '<asp>explanation of concepts</asp><opn>hardly any</opn><cat>Staff - Teaching</cat><sen>negative</sen>', '<asp>concepts</asp><opn>confused</opn><cat>Staff - Teaching</cat><sen>negative</sen>', \"<asp>this course</asp><opn>You'll learn almost nothing</opn><cat>Course - Overall</cat><sen>negative</sen>\", '<asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat><sen>negative</sen>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "15. \u001B[1;30;44m    OE    \u001B[0m\n",
      "Input:\n",
      "\u001B[33mYou can get a decent grade, but end up forgetting everything.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<opn>can get a decent grade</opn>', '<opn>forgetting everything</opn>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<opn>decent</opn>, <opn>forget everything</opn>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<opn>decent</opn>', '<opn>forget everything</opn>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "16. \u001B[1;30;44m   AOPE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mYou can get a decent grade, but end up forgetting everything.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>null</asp><opn>can get a decent grade</opn>', '<asp>null</asp><opn>forgetting everything</opn>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>null</asp><opn>decent grade</opn>, <asp>null</asp><opn>forget everything</opn>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>null</asp><opn>decent grade</opn>', '<asp>null</asp><opn>forget everything</opn>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "17. \u001B[1;30;44m   AOC    \u001B[0m\n",
      "Input:\n",
      "\u001B[33mYou can get a decent grade, but end up forgetting everything.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>null</asp><opn>can get a decent grade</opn><cat>Course - Difficulty</cat>', '<asp>null</asp><opn>forgetting everything</opn><cat>Course - Overall</cat>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>null</asp><opn>decent grade</opn><cat>Course - Overall</cat>, <asp>null</asp><opn>forget everything</opn><cat>Course - Overall</cat>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>null</asp><opn>decent grade</opn><cat>Course - Overall</cat>', '<asp>null</asp><opn>forget everything</opn><cat>Course - Overall</cat>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "18. \u001B[1;30;44m   ASTE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mYou can get a decent grade, but end up forgetting everything.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>null</asp><opn>can get a decent grade</opn><sen>positive</sen>', '<asp>null</asp><opn>forgetting everything</opn><sen>negative</sen>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>null</asp><opn>decent grade</opn><sen>positive</sen>, <asp>null</asp><opn>forget everything</opn><sen>negative</sen>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>null</asp><opn>decent grade</opn><sen>positive</sen>', '<asp>null</asp><opn>forget everything</opn><sen>negative</sen>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n",
      "19. \u001B[1;30;44m   ASQE   \u001B[0m\n",
      "Input:\n",
      "\u001B[33mYou can get a decent grade, but end up forgetting everything.\u001B[0m\n",
      "ground_truth:\u001B[32m\n",
      "['<asp>null</asp><opn>can get a decent grade</opn><cat>Course - Difficulty</cat><sen>positive</sen>', '<asp>null</asp><opn>forgetting everything</opn><cat>Course - Overall</cat><sen>negative</sen>']\u001B[0m\n",
      "raw_pred:\u001B[35m\n",
      "{'\"[<asp>null</asp><opn>decent grade</opn><cat>Course - Overall</cat><sen>positive</sen>, <asp>null</asp><opn>forget everything</opn><cat>Course - Overall</cat><sen>negative</sen>]\"'}\u001B[0m\n",
      "prediction:\u001B[36m\n",
      "['<asp>null</asp><opn>decent grade</opn><cat>Course - Overall</cat><sen>positive</sen>', '<asp>null</asp><opn>forget everything</opn><cat>Course - Overall</cat><sen>negative</sen>']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.208387Z",
     "start_time": "2025-11-06T10:25:41.206237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_results = model_output['results']\n",
    "\n",
    "print(f\"sft_output:             {model_output.keys()}\\n\")\n",
    "print(f\"sft_output['results']:  {eval_results.keys()}\\n\")"
   ],
   "id": "7502a327427b351a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sft_output:             dict_keys(['all_preds', 'all_labels', 'eval_input', 'results'])\n",
      "\n",
      "sft_output['results']:  dict_keys(['dataframes', 'match_details_dict', 'input_dict'])\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='magenta'>Write eval_input and processed input_dict to file</font>",
   "id": "82e73ce1a925e569"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.358714Z",
     "start_time": "2025-11-06T10:25:41.355069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_input = model_output.get('eval_input', dict())\n",
    "\n",
    "eval_input_dict = eval_results.get('input_dict', dict())\n",
    "\n",
    "print(len(eval_input), len(eval_input_dict))\n",
    "\n",
    "\n",
    "# if not os.path.exists(eval_input_dict_dir):\n",
    "print(test_input_dict_dir)\n",
    "with open (test_input_dict_dir, 'a', encoding='utf-8') as dictfile:  # use 'a' mode to append instead of overwrite. \n",
    "    print(f\"eval_input = {eval_input}\", file=dictfile)    \n",
    "    print(f\"sft_input_dict = {eval_input_dict}\", file=dictfile)\n",
    "    print(f\"\\033[33mwriting to dict: {test_input_dict_dir}\\033[0m\\n\")\n",
    "# else:\n",
    "#     print(f\"\\n\\u001b[4m\\u001b[44m{eval_input_dict_dir} file already written, check if need overwrite\\033[0m\\n\")\n"
   ],
   "id": "df216c72e2c3f0e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20\n",
      "../OUTPUTS/OUTPUT_1_final_test_output_files/_demo/test_input_merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot_(2025-11-06).py\n",
      "\u001B[33mwriting to dict: ../OUTPUTS/OUTPUT_1_final_test_output_files/_demo/test_input_merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot_(2025-11-06).py\u001B[0m\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.384080Z",
     "start_time": "2025-11-06T10:25:41.366188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_result_dfdict = eval_results.get('dataframes', dict())\n",
    "\n",
    "eval_result_dfdict['task_summary_df'] = evaluator._transpose_df(eval_result_dfdict['task_summary_df'], 'merged')\n",
    "\n",
    "print(f\"{eval_result_dfdict.keys()}\\n\\n\")"
   ],
   "id": "72ace3f4d43f900",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['task_summary_df', 'entries_metrics_df', 'pairs_metrics_df', 'match_details_df'])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### <font color='magenta'>Write df to dict</font>",
   "id": "bff06d02d15b1c45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.441542Z",
     "start_time": "2025-11-06T10:25:41.439522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for df_name, df in eval_result_dfdict.items(): \n",
    "    sheetname_df_dict[f\"SFT_{df_name}\"] = df\n",
    "    print(f'\\033[36m{df_name:<20}   len = \\033[0m{len(df)}')"
   ],
   "id": "bff4267805341ff4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36mtask_summary_df        len = \u001B[0m60\n",
      "\u001B[36mentries_metrics_df     len = \u001B[0m20\n",
      "\u001B[36mpairs_metrics_df       len = \u001B[0m90\n",
      "\u001B[36mmatch_details_df       len = \u001B[0m96\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.499079Z",
     "start_time": "2025-11-06T10:25:41.492800Z"
    }
   },
   "cell_type": "code",
   "source": "eval_result_dfdict['task_summary_df']",
   "id": "d1a86fe6e3be0762",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             task_type merged OE merged AOPE merged AOC  \\\n",
       "0                          entry_count         4           4          4   \n",
       "1                           total_pred        20          18         20   \n",
       "2                           total_gold        18          18         18   \n",
       "3                        total_matched        18          18         18   \n",
       "4                        unit_match_TP        15          15         10   \n",
       "5                        unit_match_FP         5           3         10   \n",
       "6                        unit_match_FN         3           3          8   \n",
       "7           unit_match_micro_precision      0.75    0.833333        0.5   \n",
       "8              unit_match_micro_recall  0.833333    0.833333   0.555556   \n",
       "9                  unit_match_micro_f1  0.789474    0.833333   0.526316   \n",
       "10          unit_match_macro_precision  0.616071    0.803571     0.4375   \n",
       "11             unit_match_macro_recall    0.6875    0.803571   0.466071   \n",
       "12                 unit_match_macro_f1  0.645833    0.803571   0.449405   \n",
       "13  weighted_component_macro_precision  0.616071    0.901786   0.752976   \n",
       "14     weighted_component_macro_recall    0.6875    0.901786   0.805357   \n",
       "15         weighted_component_macro_f1  0.645833    0.901786   0.774802   \n",
       "16                           aspect_TP       NaN        16.0       13.0   \n",
       "17                           aspect_FP       NaN         2.0        7.0   \n",
       "18                           aspect_FN       NaN         2.0        5.0   \n",
       "19              aspect_micro_precision       NaN    0.888889       0.65   \n",
       "20                 aspect_micro_recall       NaN    0.888889   0.722222   \n",
       "21                     aspect_micro_f1       NaN    0.888889   0.684211   \n",
       "22              aspect_macro_precision       NaN    0.928571       0.75   \n",
       "23                 aspect_macro_recall       NaN    0.928571   0.778571   \n",
       "24                     aspect_macro_f1       NaN    0.928571   0.761905   \n",
       "25       aspect_overall_avg_similarity       NaN    0.928571   0.778571   \n",
       "26       aspect_overall_std_similarity       NaN    0.123718   0.247745   \n",
       "27                          opinion_TP        15          17         17   \n",
       "28                          opinion_FP         5           1          3   \n",
       "29                          opinion_FN         3           1          1   \n",
       "30             opinion_micro_precision      0.75    0.944444       0.85   \n",
       "31                opinion_micro_recall  0.833333    0.944444   0.944444   \n",
       "32                    opinion_micro_f1  0.789474    0.944444   0.894737   \n",
       "33             opinion_macro_precision  0.616071       0.875   0.803571   \n",
       "34                opinion_macro_recall    0.6875       0.875      0.875   \n",
       "35                    opinion_macro_f1  0.645833       0.875   0.833333   \n",
       "36      opinion_overall_avg_similarity  0.759735    0.812413   0.812413   \n",
       "37      opinion_overall_std_similarity  0.328288    0.276881   0.276881   \n",
       "38                         category_TP       NaN         NaN       15.0   \n",
       "39                         category_FP       NaN         NaN        5.0   \n",
       "40                         category_FN       NaN         NaN        3.0   \n",
       "41            category_micro_precision       NaN         NaN       0.75   \n",
       "42               category_micro_recall       NaN         NaN   0.833333   \n",
       "43                   category_micro_f1       NaN         NaN   0.789474   \n",
       "44            category_macro_precision       NaN         NaN   0.705357   \n",
       "45               category_macro_recall       NaN         NaN     0.7625   \n",
       "46                   category_macro_f1       NaN         NaN   0.729167   \n",
       "47     category_overall_avg_similarity       NaN         NaN    0.83375   \n",
       "48     category_overall_std_similarity       NaN         NaN   0.124668   \n",
       "49                        sentiment_TP       NaN         NaN        NaN   \n",
       "50                        sentiment_FP       NaN         NaN        NaN   \n",
       "51                        sentiment_FN       NaN         NaN        NaN   \n",
       "52           sentiment_micro_precision       NaN         NaN        NaN   \n",
       "53              sentiment_micro_recall       NaN         NaN        NaN   \n",
       "54                  sentiment_micro_f1       NaN         NaN        NaN   \n",
       "55           sentiment_macro_precision       NaN         NaN        NaN   \n",
       "56              sentiment_macro_recall       NaN         NaN        NaN   \n",
       "57                  sentiment_macro_f1       NaN         NaN        NaN   \n",
       "58    sentiment_overall_avg_similarity       NaN         NaN        NaN   \n",
       "59    sentiment_overall_std_similarity       NaN         NaN        NaN   \n",
       "\n",
       "   merged ASTE merged ASQE  \n",
       "0            4           4  \n",
       "1           18          20  \n",
       "2           18          18  \n",
       "3           18          18  \n",
       "4           15          11  \n",
       "5            3           9  \n",
       "6            3           7  \n",
       "7     0.833333        0.55  \n",
       "8     0.833333    0.611111  \n",
       "9     0.833333    0.578947  \n",
       "10    0.803571         0.5  \n",
       "11    0.803571    0.528571  \n",
       "12    0.803571    0.511905  \n",
       "13    0.934524      0.8125  \n",
       "14    0.934524    0.869643  \n",
       "15    0.934524     0.83631  \n",
       "16        16.0        13.0  \n",
       "17         2.0         7.0  \n",
       "18         2.0         5.0  \n",
       "19    0.888889        0.65  \n",
       "20    0.888889    0.722222  \n",
       "21    0.888889    0.684211  \n",
       "22    0.928571        0.75  \n",
       "23    0.928571    0.778571  \n",
       "24    0.928571    0.761905  \n",
       "25    0.928571    0.778571  \n",
       "26    0.123718    0.247745  \n",
       "27          17          17  \n",
       "28           1           3  \n",
       "29           1           1  \n",
       "30    0.944444        0.85  \n",
       "31    0.944444    0.944444  \n",
       "32    0.944444    0.894737  \n",
       "33       0.875    0.803571  \n",
       "34       0.875       0.875  \n",
       "35       0.875    0.833333  \n",
       "36    0.812413    0.812413  \n",
       "37    0.276881    0.276881  \n",
       "38         NaN        16.0  \n",
       "39         NaN         4.0  \n",
       "40         NaN         2.0  \n",
       "41         NaN         0.8  \n",
       "42         NaN    0.888889  \n",
       "43         NaN    0.842105  \n",
       "44         NaN    0.767857  \n",
       "45         NaN       0.825  \n",
       "46         NaN    0.791667  \n",
       "47         NaN      0.8775  \n",
       "48         NaN    0.143244  \n",
       "49        18.0        18.0  \n",
       "50         0.0         2.0  \n",
       "51         0.0         0.0  \n",
       "52         1.0         0.9  \n",
       "53         1.0         1.0  \n",
       "54         1.0    0.947368  \n",
       "55         1.0    0.928571  \n",
       "56         1.0         1.0  \n",
       "57         1.0    0.958333  \n",
       "58         1.0         1.0  \n",
       "59         0.0         0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_type</th>\n",
       "      <th>merged OE</th>\n",
       "      <th>merged AOPE</th>\n",
       "      <th>merged AOC</th>\n",
       "      <th>merged ASTE</th>\n",
       "      <th>merged ASQE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entry_count</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_pred</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_gold</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_matched</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unit_match_TP</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unit_match_FP</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unit_match_FN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unit_match_micro_precision</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unit_match_micro_recall</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unit_match_micro_f1</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>unit_match_macro_precision</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>unit_match_macro_recall</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.466071</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.528571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>unit_match_macro_f1</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.449405</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.511905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>weighted_component_macro_precision</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.752976</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>weighted_component_macro_recall</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.805357</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.869643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>weighted_component_macro_f1</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.774802</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.83631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aspect_TP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aspect_FP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aspect_FN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aspect_micro_precision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aspect_micro_recall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aspect_micro_f1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aspect_macro_precision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>aspect_macro_recall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.778571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>aspect_macro_f1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aspect_overall_avg_similarity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.778571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.778571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aspect_overall_std_similarity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123718</td>\n",
       "      <td>0.247745</td>\n",
       "      <td>0.123718</td>\n",
       "      <td>0.247745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>opinion_TP</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>opinion_FP</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>opinion_FN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>opinion_micro_precision</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>opinion_micro_recall</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>opinion_micro_f1</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>opinion_macro_precision</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>opinion_macro_recall</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>opinion_macro_f1</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>opinion_overall_avg_similarity</td>\n",
       "      <td>0.759735</td>\n",
       "      <td>0.812413</td>\n",
       "      <td>0.812413</td>\n",
       "      <td>0.812413</td>\n",
       "      <td>0.812413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>opinion_overall_std_similarity</td>\n",
       "      <td>0.328288</td>\n",
       "      <td>0.276881</td>\n",
       "      <td>0.276881</td>\n",
       "      <td>0.276881</td>\n",
       "      <td>0.276881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>category_TP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>category_FP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>category_FN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>category_micro_precision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>category_micro_recall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>category_micro_f1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>category_macro_precision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>category_macro_recall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>category_macro_f1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>category_overall_avg_similarity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.83375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>category_overall_std_similarity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sentiment_TP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>sentiment_FP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>sentiment_FN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sentiment_micro_precision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>sentiment_micro_recall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>sentiment_micro_f1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>sentiment_macro_precision</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>sentiment_macro_recall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>sentiment_macro_f1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>sentiment_overall_avg_similarity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>sentiment_overall_std_similarity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.575957Z",
     "start_time": "2025-11-06T10:25:41.569261Z"
    }
   },
   "cell_type": "code",
   "source": "eval_result_dfdict['pairs_metrics_df']",
   "id": "ef243920c3fcb0f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    entry_id task_type   pair_id  is_unit_match  aspect_score  opinion_score  \\\n",
       "0          0        OE   0-g3-p0           True           NaN       1.000000   \n",
       "1          0        OE   0-g4-p1           True           NaN       1.000000   \n",
       "2          0        OE   0-g0-p2           True           NaN       0.933333   \n",
       "3          0        OE   0-g1-p3           True           NaN       1.000000   \n",
       "4          0        OE   0-g2-p4           True           NaN       1.000000   \n",
       "..       ...       ...       ...            ...           ...            ...   \n",
       "85        17       AOC  17-g1-p1          False           1.0       0.000000   \n",
       "86        18      ASTE  18-g0-p0           True           1.0       0.666667   \n",
       "87        18      ASTE  18-g1-p1          False           1.0       0.000000   \n",
       "88        19      ASQE  19-g0-p0          False           1.0       0.666667   \n",
       "89        19      ASQE  19-g1-p1          False           1.0       0.000000   \n",
       "\n",
       "    category_score  sentiment_score  \\\n",
       "0              NaN              NaN   \n",
       "1              NaN              NaN   \n",
       "2              NaN              NaN   \n",
       "3              NaN              NaN   \n",
       "4              NaN              NaN   \n",
       "..             ...              ...   \n",
       "85             1.0              NaN   \n",
       "86             NaN              1.0   \n",
       "87             NaN              1.0   \n",
       "88             0.3              1.0   \n",
       "89             1.0              1.0   \n",
       "\n",
       "                                            gold_item  \\\n",
       "0                        <opn>good mark booster</opn>   \n",
       "1                  <opn>not particularly useful</opn>   \n",
       "2   <opn>Not as interesting as I thought it would ...   \n",
       "3                                      <opn>dry</opn>   \n",
       "4                          <opn>put me to sleep</opn>   \n",
       "..                                                ...   \n",
       "85  <asp>null</asp><opn>forgetting everything</opn...   \n",
       "86  <asp>null</asp><opn>can get a decent grade</op...   \n",
       "87  <asp>null</asp><opn>forgetting everything</opn...   \n",
       "88  <asp>null</asp><opn>can get a decent grade</op...   \n",
       "89  <asp>null</asp><opn>forgetting everything</opn...   \n",
       "\n",
       "                                            pred_item  weighted_score  \n",
       "0                        <opn>good mark booster</opn>        1.000000  \n",
       "1                  <opn>not particularly useful</opn>        1.000000  \n",
       "2   <opn>Not as interesting as I thought it would ...        0.933333  \n",
       "3                                      <opn>dry</opn>        1.000000  \n",
       "4                          <opn>put me to sleep</opn>        1.000000  \n",
       "..                                                ...             ...  \n",
       "85  <asp>null</asp><opn>forget everything</opn><ca...        0.666667  \n",
       "86  <asp>null</asp><opn>decent grade</opn><sen>pos...        0.888889  \n",
       "87  <asp>null</asp><opn>forget everything</opn><se...        0.666667  \n",
       "88  <asp>null</asp><opn>decent grade</opn><cat>Cou...        0.741667  \n",
       "89  <asp>null</asp><opn>forget everything</opn><ca...        0.750000  \n",
       "\n",
       "[90 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>task_type</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>is_unit_match</th>\n",
       "      <th>aspect_score</th>\n",
       "      <th>opinion_score</th>\n",
       "      <th>category_score</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>gold_item</th>\n",
       "      <th>pred_item</th>\n",
       "      <th>weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g3-p0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;opn&gt;good mark booster&lt;/opn&gt;</td>\n",
       "      <td>&lt;opn&gt;good mark booster&lt;/opn&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g4-p1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;opn&gt;not particularly useful&lt;/opn&gt;</td>\n",
       "      <td>&lt;opn&gt;not particularly useful&lt;/opn&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g0-p2</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;opn&gt;Not as interesting as I thought it would ...</td>\n",
       "      <td>&lt;opn&gt;Not as interesting as I thought it would ...</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g1-p3</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;opn&gt;dry&lt;/opn&gt;</td>\n",
       "      <td>&lt;opn&gt;dry&lt;/opn&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g2-p4</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;opn&gt;put me to sleep&lt;/opn&gt;</td>\n",
       "      <td>&lt;opn&gt;put me to sleep&lt;/opn&gt;</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>17</td>\n",
       "      <td>AOC</td>\n",
       "      <td>17-g1-p1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;forgetting everything&lt;/opn...</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;forget everything&lt;/opn&gt;&lt;ca...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>18</td>\n",
       "      <td>ASTE</td>\n",
       "      <td>18-g0-p0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;can get a decent grade&lt;/op...</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;decent grade&lt;/opn&gt;&lt;sen&gt;pos...</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>18</td>\n",
       "      <td>ASTE</td>\n",
       "      <td>18-g1-p1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;forgetting everything&lt;/opn...</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;forget everything&lt;/opn&gt;&lt;se...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>19</td>\n",
       "      <td>ASQE</td>\n",
       "      <td>19-g0-p0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;can get a decent grade&lt;/op...</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;decent grade&lt;/opn&gt;&lt;cat&gt;Cou...</td>\n",
       "      <td>0.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>19</td>\n",
       "      <td>ASQE</td>\n",
       "      <td>19-g1-p1</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;forgetting everything&lt;/opn...</td>\n",
       "      <td>&lt;asp&gt;null&lt;/asp&gt;&lt;opn&gt;forget everything&lt;/opn&gt;&lt;ca...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.610375Z",
     "start_time": "2025-11-06T10:25:41.601135Z"
    }
   },
   "cell_type": "code",
   "source": "eval_result_dfdict['match_details_df']",
   "id": "8b539320c8908fdb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    entry_id  Task    PairID  is_optimal_match  is_unit_match  \\\n",
       "0          0    OE   0-g0-p2              True           True   \n",
       "1          0    OE   0-g1-p3              True           True   \n",
       "2          0    OE   0-g2-p4              True           True   \n",
       "3          0    OE   0-g3-p0              True           True   \n",
       "4          0    OE   0-g4-p1              True           True   \n",
       "..       ...   ...       ...               ...            ...   \n",
       "91        17   AOC  17-g1-p1              True          False   \n",
       "92        18  ASTE  18-g0-p0              True           True   \n",
       "93        18  ASTE  18-g1-p1              True          False   \n",
       "94        19  ASQE  19-g0-p0              True          False   \n",
       "95        19  ASQE  19-g1-p1              True          False   \n",
       "\n",
       "                                           Input Text Match Quality  \\\n",
       "0   Studied for the exam literally the day of... e...  Strong Match   \n",
       "1   Studied for the exam literally the day of... e...    Full Match   \n",
       "2   Studied for the exam literally the day of... e...    Full Match   \n",
       "3   Studied for the exam literally the day of... e...    Full Match   \n",
       "4   Studied for the exam literally the day of... e...    Full Match   \n",
       "..                                                ...           ...   \n",
       "91  You can get a decent grade, but end up forgett...    Good Match   \n",
       "92  You can get a decent grade, but end up forgett...  Strong Match   \n",
       "93  You can get a decent grade, but end up forgett...    Good Match   \n",
       "94  You can get a decent grade, but end up forgett...    Good Match   \n",
       "95  You can get a decent grade, but end up forgett...    Good Match   \n",
       "\n",
       "   Gold-Aspect Pred-Aspect  Aspect Score  \\\n",
       "0          NaN         NaN           NaN   \n",
       "1          NaN         NaN           NaN   \n",
       "2          NaN         NaN           NaN   \n",
       "3          NaN         NaN           NaN   \n",
       "4          NaN         NaN           NaN   \n",
       "..         ...         ...           ...   \n",
       "91        null        null           1.0   \n",
       "92        null        null           1.0   \n",
       "93        null        null           1.0   \n",
       "94        null        null           1.0   \n",
       "95        null        null           1.0   \n",
       "\n",
       "                                       Gold-Opinion  \\\n",
       "0   Not as interesting as I thought it would be tho   \n",
       "1                                               dry   \n",
       "2                                   put me to sleep   \n",
       "3                                 good mark booster   \n",
       "4                           not particularly useful   \n",
       "..                                              ...   \n",
       "91                            forgetting everything   \n",
       "92                           can get a decent grade   \n",
       "93                            forgetting everything   \n",
       "94                           can get a decent grade   \n",
       "95                            forgetting everything   \n",
       "\n",
       "                                   Pred-Opinion  Opinion Score  \\\n",
       "0   Not as interesting as I thought it would be       0.933333   \n",
       "1                                           dry       1.000000   \n",
       "2                               put me to sleep       1.000000   \n",
       "3                             good mark booster       1.000000   \n",
       "4                       not particularly useful       1.000000   \n",
       "..                                          ...            ...   \n",
       "91                            forget everything       0.000000   \n",
       "92                                 decent grade       0.666667   \n",
       "93                            forget everything       0.000000   \n",
       "94                                 decent grade       0.666667   \n",
       "95                            forget everything       0.000000   \n",
       "\n",
       "          Gold-Category     Pred-Category  Category Score Gold-Sentiment  \\\n",
       "0                   NaN               NaN             NaN            NaN   \n",
       "1                   NaN               NaN             NaN            NaN   \n",
       "2                   NaN               NaN             NaN            NaN   \n",
       "3                   NaN               NaN             NaN            NaN   \n",
       "4                   NaN               NaN             NaN            NaN   \n",
       "..                  ...               ...             ...            ...   \n",
       "91     Course - Overall  Course - Overall             1.0            NaN   \n",
       "92                  NaN               NaN             NaN       positive   \n",
       "93                  NaN               NaN             NaN       negative   \n",
       "94  Course - Difficulty  Course - Overall             0.3       positive   \n",
       "95     Course - Overall  Course - Overall             1.0       negative   \n",
       "\n",
       "   Pred-Sentiment  Sentiment Score  Overall Score  \n",
       "0             NaN              NaN       0.933333  \n",
       "1             NaN              NaN       1.000000  \n",
       "2             NaN              NaN       1.000000  \n",
       "3             NaN              NaN       1.000000  \n",
       "4             NaN              NaN       1.000000  \n",
       "..            ...              ...            ...  \n",
       "91            NaN              NaN       0.666667  \n",
       "92       positive              1.0       0.888889  \n",
       "93       negative              1.0       0.666667  \n",
       "94       positive              1.0       0.741667  \n",
       "95       negative              1.0       0.750000  \n",
       "\n",
       "[96 rows x 20 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>Task</th>\n",
       "      <th>PairID</th>\n",
       "      <th>is_optimal_match</th>\n",
       "      <th>is_unit_match</th>\n",
       "      <th>Input Text</th>\n",
       "      <th>Match Quality</th>\n",
       "      <th>Gold-Aspect</th>\n",
       "      <th>Pred-Aspect</th>\n",
       "      <th>Aspect Score</th>\n",
       "      <th>Gold-Opinion</th>\n",
       "      <th>Pred-Opinion</th>\n",
       "      <th>Opinion Score</th>\n",
       "      <th>Gold-Category</th>\n",
       "      <th>Pred-Category</th>\n",
       "      <th>Category Score</th>\n",
       "      <th>Gold-Sentiment</th>\n",
       "      <th>Pred-Sentiment</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Overall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g0-p2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Studied for the exam literally the day of... e...</td>\n",
       "      <td>Strong Match</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not as interesting as I thought it would be tho</td>\n",
       "      <td>Not as interesting as I thought it would be</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g1-p3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Studied for the exam literally the day of... e...</td>\n",
       "      <td>Full Match</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g2-p4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Studied for the exam literally the day of... e...</td>\n",
       "      <td>Full Match</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>put me to sleep</td>\n",
       "      <td>put me to sleep</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g3-p0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Studied for the exam literally the day of... e...</td>\n",
       "      <td>Full Match</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good mark booster</td>\n",
       "      <td>good mark booster</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>OE</td>\n",
       "      <td>0-g4-p1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Studied for the exam literally the day of... e...</td>\n",
       "      <td>Full Match</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not particularly useful</td>\n",
       "      <td>not particularly useful</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>17</td>\n",
       "      <td>AOC</td>\n",
       "      <td>17-g1-p1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>You can get a decent grade, but end up forgett...</td>\n",
       "      <td>Good Match</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>1.0</td>\n",
       "      <td>forgetting everything</td>\n",
       "      <td>forget everything</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Course - Overall</td>\n",
       "      <td>Course - Overall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>18</td>\n",
       "      <td>ASTE</td>\n",
       "      <td>18-g0-p0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>You can get a decent grade, but end up forgett...</td>\n",
       "      <td>Strong Match</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>1.0</td>\n",
       "      <td>can get a decent grade</td>\n",
       "      <td>decent grade</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>18</td>\n",
       "      <td>ASTE</td>\n",
       "      <td>18-g1-p1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>You can get a decent grade, but end up forgett...</td>\n",
       "      <td>Good Match</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>1.0</td>\n",
       "      <td>forgetting everything</td>\n",
       "      <td>forget everything</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>19</td>\n",
       "      <td>ASQE</td>\n",
       "      <td>19-g0-p0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>You can get a decent grade, but end up forgett...</td>\n",
       "      <td>Good Match</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>1.0</td>\n",
       "      <td>can get a decent grade</td>\n",
       "      <td>decent grade</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Course - Difficulty</td>\n",
       "      <td>Course - Overall</td>\n",
       "      <td>0.3</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>19</td>\n",
       "      <td>ASQE</td>\n",
       "      <td>19-g1-p1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>You can get a decent grade, but end up forgett...</td>\n",
       "      <td>Good Match</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>1.0</td>\n",
       "      <td>forgetting everything</td>\n",
       "      <td>forget everything</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Course - Overall</td>\n",
       "      <td>Course - Overall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows  20 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.741495Z",
     "start_time": "2025-11-06T10:25:41.737139Z"
    }
   },
   "cell_type": "code",
   "source": "eval_input_dict",
   "id": "bd5db9302a328e0a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'task_type': 'OE',\n",
       "  'input_text': 'Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.',\n",
       "  'label': ['<opn>Not as interesting as I thought it would be tho</opn>',\n",
       "   '<opn>dry</opn>',\n",
       "   '<opn>put me to sleep</opn>',\n",
       "   '<opn>good mark booster</opn>',\n",
       "   '<opn>not particularly useful</opn>'],\n",
       "  'pred': ['<opn>good mark booster</opn>',\n",
       "   '<opn>not particularly useful</opn>',\n",
       "   '<opn>Not as interesting as I thought it would be</opn>',\n",
       "   '<opn>dry</opn>',\n",
       "   '<opn>put me to sleep</opn>',\n",
       "   '<opn>good mark booster</opn>',\n",
       "   '<opn>not particularly useful</opn>']},\n",
       " 1: {'task_type': 'AOPE',\n",
       "  'input_text': 'Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.',\n",
       "  'label': ['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn>',\n",
       "   '<asp>textbook</asp><opn>dry</opn>',\n",
       "   '<asp>lectures</asp><opn>put me to sleep</opn>',\n",
       "   '<asp>null</asp><opn>good mark booster</opn>',\n",
       "   '<asp>null</asp><opn>not particularly useful</opn>'],\n",
       "  'pred': ['<asp>null</asp><opn>not as interesting as I thought it would be</opn>',\n",
       "   '<asp>textbook</asp><opn>dry</opn>',\n",
       "   '<asp>lectures</asp><opn>put me to sleep</opn>',\n",
       "   '<asp>null</asp><opn>good mark booster</opn>',\n",
       "   '<asp>null</asp><opn>not particularly useful</opn>']},\n",
       " 2: {'task_type': 'AOC',\n",
       "  'input_text': 'Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.',\n",
       "  'label': ['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn><cat>Course - Overall</cat>',\n",
       "   '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat>',\n",
       "   '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat>',\n",
       "   '<asp>null</asp><opn>good mark booster</opn><cat>Course - Difficulty</cat>',\n",
       "   '<asp>null</asp><opn>not particularly useful</opn><cat>Course - Overall</cat>'],\n",
       "  'pred': ['<asp>exam</asp><opn>literally the day of</opn><cat>Course - Assessment</cat>',\n",
       "   '<asp>exam</asp><opn>90%</opn><cat>Course - Assessment</cat>',\n",
       "   '<asp>exam</asp><opn>Not as interesting as I thought it would be</opn><cat>Course - Overall</cat>',\n",
       "   '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat>',\n",
       "   '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat>',\n",
       "   '<asp>course</asp><opn>good mark booster</opn><cat>Course - Overall</cat>',\n",
       "   '<asp>course</asp><opn>not particularly useful</opn><cat>Course - Overall</cat>']},\n",
       " 3: {'task_type': 'ASTE',\n",
       "  'input_text': 'Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.',\n",
       "  'label': ['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn><sen>negative</sen>',\n",
       "   '<asp>textbook</asp><opn>dry</opn><sen>negative</sen>',\n",
       "   '<asp>lectures</asp><opn>put me to sleep</opn><sen>negative</sen>',\n",
       "   '<asp>null</asp><opn>good mark booster</opn><sen>positive</sen>',\n",
       "   '<asp>null</asp><opn>not particularly useful</opn><sen>negative</sen>'],\n",
       "  'pred': ['<asp>null</asp><opn>not as interesting as I thought it would be</opn><sen>negative</sen>',\n",
       "   '<asp>textbook</asp><opn>dry</opn><sen>negative</sen>',\n",
       "   '<asp>lectures</asp><opn>put me to sleep</opn><sen>negative</sen>',\n",
       "   '<asp>null</asp><opn>good mark booster</opn><sen>positive</sen>',\n",
       "   '<asp>null</asp><opn>not particularly useful</opn><sen>negative</sen>']},\n",
       " 4: {'task_type': 'ASQE',\n",
       "  'input_text': 'Studied for the exam literally the day of... ended with a 90% lol. Not as interesting as I thought it would be tho. The textbook is dry, and the lectures put me to sleep. Overall a good mark booster, but not particularly useful.',\n",
       "  'label': ['<asp>null</asp><opn>Not as interesting as I thought it would be tho</opn><cat>Course - Overall</cat><sen>negative</sen>',\n",
       "   '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat><sen>negative</sen>',\n",
       "   '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat><sen>negative</sen>',\n",
       "   '<asp>null</asp><opn>good mark booster</opn><cat>Course - Difficulty</cat><sen>positive</sen>',\n",
       "   '<asp>null</asp><opn>not particularly useful</opn><cat>Course - Overall</cat><sen>negative</sen>'],\n",
       "  'pred': ['<asp>exam</asp><opn>literally the day of</opn><cat>Course - Assessment</cat><sen>neutral</sen>',\n",
       "   '<asp>exam</asp><opn>90%</opn><cat>Course - Assessment</cat><sen>positive</sen>',\n",
       "   '<asp>exam</asp><opn>Not as interesting as I thought it would be</opn><cat>Course - Overall</cat><sen>negative</sen>',\n",
       "   '<asp>textbook</asp><opn>dry</opn><cat>Course - Course materials</cat><sen>negative</sen>',\n",
       "   '<asp>lectures</asp><opn>put me to sleep</opn><cat>Course - Learning activity</cat><sen>negative</sen>',\n",
       "   '<asp>course</asp><opn>good mark booster</opn><cat>Course - Overall</cat><sen>positive</sen>',\n",
       "   '<asp>course</asp><opn>not particularly useful</opn><cat>Course - Overall</cat><sen>negative</sen>']},\n",
       " 5: {'task_type': 'OE',\n",
       "  'input_text': 'The campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.',\n",
       "  'label': ['<opn>a beautiful place to work</opn>',\n",
       "   '<opn>very green</opn>',\n",
       "   '<opn>outstanding</opn>',\n",
       "   '<opn>clearly striving for the best in every student</opn>'],\n",
       "  'pred': ['<opn>very green</opn>',\n",
       "   '<opn>beautiful</opn>',\n",
       "   '<opn>outstanding</opn>',\n",
       "   '<opn>striving for the best in every student</opn>']},\n",
       " 6: {'task_type': 'AOPE',\n",
       "  'input_text': 'The campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.',\n",
       "  'label': ['<asp>campus</asp><opn>a beautiful place to work</opn>',\n",
       "   '<asp>campus</asp><opn>very green</opn>',\n",
       "   '<asp>facilities</asp><opn>outstanding</opn>',\n",
       "   '<asp>staff</asp><opn>clearly striving for the best in every student</opn>'],\n",
       "  'pred': ['<asp>campus</asp><opn>very green</opn>',\n",
       "   '<asp>campus</asp><opn>beautiful place to work</opn>',\n",
       "   '<asp>facilities</asp><opn>outstanding</opn>',\n",
       "   '<asp>staff</asp><opn>striving for the best in every student</opn>']},\n",
       " 7: {'task_type': 'AOC',\n",
       "  'input_text': 'The campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.',\n",
       "  'label': ['<asp>campus</asp><opn>a beautiful place to work</opn><cat>University - Campus & facilities</cat>',\n",
       "   '<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat>',\n",
       "   '<asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat>',\n",
       "   '<asp>staff</asp><opn>clearly striving for the best in every student</opn><cat>Staff - Overall</cat>'],\n",
       "  'pred': ['<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat>',\n",
       "   '<asp>campus</asp><opn>beautiful place to work</opn><cat>University - Overall</cat>',\n",
       "   '<asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat>',\n",
       "   '<asp>staff</asp><opn>striving for the best in every student</opn><cat>Staff - Overall</cat>']},\n",
       " 8: {'task_type': 'ASTE',\n",
       "  'input_text': 'The campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.',\n",
       "  'label': ['<asp>campus</asp><opn>a beautiful place to work</opn><sen>positive</sen>',\n",
       "   '<asp>campus</asp><opn>very green</opn><sen>positive</sen>',\n",
       "   '<asp>facilities</asp><opn>outstanding</opn><sen>positive</sen>',\n",
       "   '<asp>staff</asp><opn>clearly striving for the best in every student</opn><sen>positive</sen>'],\n",
       "  'pred': ['<asp>campus</asp><opn>very green</opn><sen>positive</sen>',\n",
       "   '<asp>campus</asp><opn>beautiful place to work</opn><sen>positive</sen>',\n",
       "   '<asp>facilities</asp><opn>outstanding</opn><sen>positive</sen>',\n",
       "   '<asp>staff</asp><opn>striving for the best in every student</opn><sen>positive</sen>']},\n",
       " 9: {'task_type': 'ASQE',\n",
       "  'input_text': 'The campus is very green, and a beautiful place to work. There are outstanding facilities in each department and a staff that are clearly striving for the best in every student.',\n",
       "  'label': ['<asp>campus</asp><opn>a beautiful place to work</opn><cat>University - Campus & facilities</cat><sen>positive</sen>',\n",
       "   '<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat><sen>positive</sen>',\n",
       "   '<asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat><sen>positive</sen>',\n",
       "   '<asp>staff</asp><opn>clearly striving for the best in every student</opn><cat>Staff - Overall</cat><sen>positive</sen>'],\n",
       "  'pred': ['<asp>campus</asp><opn>very green</opn><cat>University - Campus & facilities</cat><sen>positive</sen>',\n",
       "   '<asp>campus</asp><opn>beautiful place to work</opn><cat>University - Campus & facilities</cat><sen>positive</sen>',\n",
       "   '<asp>facilities</asp><opn>outstanding</opn><cat>University - Campus & facilities</cat><sen>positive</sen>',\n",
       "   '<asp>staff</asp><opn>striving for the best in every student</opn><cat>Staff - Overall</cat><sen>positive</sen>']},\n",
       " 10: {'task_type': 'OE',\n",
       "  'input_text': \"Bad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\",\n",
       "  'label': ['<opn>Bad</opn>',\n",
       "   '<opn>confused</opn>',\n",
       "   '<opn>random</opn>',\n",
       "   '<opn>disorganized</opn>',\n",
       "   '<opn>hardly any explanation of concepts</opn>',\n",
       "   \"<opn>You'll learn almost nothing</opn>\",\n",
       "   '<opn>Not recommended</opn>'],\n",
       "  'pred': ['<opn>Bad</opn>',\n",
       "   '<opn>random</opn>',\n",
       "   '<opn>disorganized</opn>',\n",
       "   '<opn>hardly any explanation of concepts</opn>',\n",
       "   '<opn>confused</opn>',\n",
       "   \"<opn>You'll learn almost nothing</opn>\",\n",
       "   '<opn>Not recommended</opn>']},\n",
       " 11: {'task_type': 'AOPE',\n",
       "  'input_text': \"Bad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\",\n",
       "  'label': ['<asp>teaching</asp><opn>Bad</opn>',\n",
       "   '<asp>teaching</asp><opn>confused</opn>',\n",
       "   '<asp>teaching</asp><opn>random</opn>',\n",
       "   '<asp>teaching</asp><opn>disorganized</opn>',\n",
       "   '<asp>teaching</asp><opn>hardly any explanation of concepts</opn>',\n",
       "   \"<asp>this course</asp><opn>You'll learn almost nothing</opn>\",\n",
       "   '<asp>this course</asp><opn>Not recommended</opn>'],\n",
       "  'pred': ['<asp>teaching</asp><opn>Bad</opn>',\n",
       "   '<asp>teaching</asp><opn>random</opn>',\n",
       "   '<asp>teaching</asp><opn>disorganized</opn>',\n",
       "   '<asp>explanation of concepts</asp><opn>hardly any</opn>',\n",
       "   '<asp>concepts</asp><opn>confused</opn>',\n",
       "   \"<asp>this course</asp><opn>You'll learn almost nothing</opn>\",\n",
       "   '<asp>this course</asp><opn>Not recommended</opn>']},\n",
       " 12: {'task_type': 'AOC',\n",
       "  'input_text': \"Bad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\",\n",
       "  'label': ['<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat>',\n",
       "   '<asp>teaching</asp><opn>confused</opn><cat>Staff - Teaching</cat>',\n",
       "   '<asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat>',\n",
       "   '<asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat>',\n",
       "   '<asp>teaching</asp><opn>hardly any explanation of concepts</opn><cat>Staff - Teaching</cat>',\n",
       "   \"<asp>this course</asp><opn>You'll learn almost nothing</opn><cat>Course - Overall</cat>\",\n",
       "   '<asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat>'],\n",
       "  'pred': ['<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat>',\n",
       "   '<asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat>',\n",
       "   '<asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat>',\n",
       "   '<asp>explanation of concepts</asp><opn>hardly any</opn><cat>Staff - Teaching</cat>',\n",
       "   '<asp>concepts</asp><opn>confused</opn><cat>Staff - Teaching</cat>',\n",
       "   \"<asp>this course</asp><opn>You'll learn almost nothing</opn><cat>Course - Overall</cat>\",\n",
       "   '<asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat>']},\n",
       " 13: {'task_type': 'ASTE',\n",
       "  'input_text': \"Bad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\",\n",
       "  'label': ['<asp>teaching</asp><opn>Bad</opn><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>confused</opn><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>random</opn><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>disorganized</opn><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>hardly any explanation of concepts</opn><sen>negative</sen>',\n",
       "   \"<asp>this course</asp><opn>You'll learn almost nothing</opn><sen>negative</sen>\",\n",
       "   '<asp>this course</asp><opn>Not recommended</opn><sen>negative</sen>'],\n",
       "  'pred': ['<asp>teaching</asp><opn>Bad</opn><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>random</opn><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>disorganized</opn><sen>negative</sen>',\n",
       "   '<asp>explanation of concepts</asp><opn>hardly any</opn><sen>negative</sen>',\n",
       "   '<asp>concepts</asp><opn>confused</opn><sen>negative</sen>',\n",
       "   \"<asp>this course</asp><opn>You'll learn almost nothing</opn><sen>negative</sen>\",\n",
       "   '<asp>this course</asp><opn>Not recommended</opn><sen>negative</sen>']},\n",
       " 14: {'task_type': 'ASQE',\n",
       "  'input_text': \"Bad teaching, random, disorganized, hardly any explanation of concepts, confused. You'll learn almost nothing by taking this course. Not recommended!\",\n",
       "  'label': ['<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>confused</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>hardly any explanation of concepts</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   \"<asp>this course</asp><opn>You'll learn almost nothing</opn><cat>Course - Overall</cat><sen>negative</sen>\",\n",
       "   '<asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat><sen>negative</sen>'],\n",
       "  'pred': ['<asp>teaching</asp><opn>Bad</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>random</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   '<asp>teaching</asp><opn>disorganized</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   '<asp>explanation of concepts</asp><opn>hardly any</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   '<asp>concepts</asp><opn>confused</opn><cat>Staff - Teaching</cat><sen>negative</sen>',\n",
       "   \"<asp>this course</asp><opn>You'll learn almost nothing</opn><cat>Course - Overall</cat><sen>negative</sen>\",\n",
       "   '<asp>this course</asp><opn>Not recommended</opn><cat>Course - Overall</cat><sen>negative</sen>']},\n",
       " 15: {'task_type': 'OE',\n",
       "  'input_text': 'You can get a decent grade, but end up forgetting everything.',\n",
       "  'label': ['<opn>can get a decent grade</opn>',\n",
       "   '<opn>forgetting everything</opn>'],\n",
       "  'pred': ['<opn>decent</opn>', '<opn>forget everything</opn>']},\n",
       " 16: {'task_type': 'AOPE',\n",
       "  'input_text': 'You can get a decent grade, but end up forgetting everything.',\n",
       "  'label': ['<asp>null</asp><opn>can get a decent grade</opn>',\n",
       "   '<asp>null</asp><opn>forgetting everything</opn>'],\n",
       "  'pred': ['<asp>null</asp><opn>decent grade</opn>',\n",
       "   '<asp>null</asp><opn>forget everything</opn>']},\n",
       " 17: {'task_type': 'AOC',\n",
       "  'input_text': 'You can get a decent grade, but end up forgetting everything.',\n",
       "  'label': ['<asp>null</asp><opn>can get a decent grade</opn><cat>Course - Difficulty</cat>',\n",
       "   '<asp>null</asp><opn>forgetting everything</opn><cat>Course - Overall</cat>'],\n",
       "  'pred': ['<asp>null</asp><opn>decent grade</opn><cat>Course - Overall</cat>',\n",
       "   '<asp>null</asp><opn>forget everything</opn><cat>Course - Overall</cat>']},\n",
       " 18: {'task_type': 'ASTE',\n",
       "  'input_text': 'You can get a decent grade, but end up forgetting everything.',\n",
       "  'label': ['<asp>null</asp><opn>can get a decent grade</opn><sen>positive</sen>',\n",
       "   '<asp>null</asp><opn>forgetting everything</opn><sen>negative</sen>'],\n",
       "  'pred': ['<asp>null</asp><opn>decent grade</opn><sen>positive</sen>',\n",
       "   '<asp>null</asp><opn>forget everything</opn><sen>negative</sen>']},\n",
       " 19: {'task_type': 'ASQE',\n",
       "  'input_text': 'You can get a decent grade, but end up forgetting everything.',\n",
       "  'label': ['<asp>null</asp><opn>can get a decent grade</opn><cat>Course - Difficulty</cat><sen>positive</sen>',\n",
       "   '<asp>null</asp><opn>forgetting everything</opn><cat>Course - Overall</cat><sen>negative</sen>'],\n",
       "  'pred': ['<asp>null</asp><opn>decent grade</opn><cat>Course - Overall</cat><sen>positive</sen>',\n",
       "   '<asp>null</asp><opn>forget everything</opn><cat>Course - Overall</cat><sen>negative</sen>']}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# <font color='gold'>Write to Excel</font>",
   "id": "2910c3d03b9a3c32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T10:25:41.843560Z",
     "start_time": "2025-11-06T10:25:41.783766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_dictToExcel(excelfilename=test_xlsx_file_dir, sheetname_df_dict=sheetname_df_dict, freezeheader=True, headerfilter=True, locksheet=False, editable_range=None)\n",
    "print(f\"\\n{green_bg}Done!  :)\\033[30m\") "
   ],
   "id": "945545f865b76795",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mSFT_task_summary_df\u001B[0m written to \u001B[33m../OUTPUTS/OUTPUT_2a_final_test_output_FTS-0BP_evaluation/_demo/test_results_merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot_(2025-11-06).xlsx.\u001B[0m\n",
      "\u001B[33mSFT_entries_metrics_df\u001B[0m written to \u001B[33m../OUTPUTS/OUTPUT_2a_final_test_output_FTS-0BP_evaluation/_demo/test_results_merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot_(2025-11-06).xlsx.\u001B[0m\n",
      "\u001B[33mSFT_pairs_metrics_df\u001B[0m written to \u001B[33m../OUTPUTS/OUTPUT_2a_final_test_output_FTS-0BP_evaluation/_demo/test_results_merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot_(2025-11-06).xlsx.\u001B[0m\n",
      "\u001B[33mSFT_match_details_df\u001B[0m written to \u001B[33m../OUTPUTS/OUTPUT_2a_final_test_output_FTS-0BP_evaluation/_demo/test_results_merged_lora_phi4mini_A46.2_train2000_R64_multitask_OE-AOPE-AOC-ASTE-ASQE_fewshot_(2025-11-06).xlsx.\u001B[0m\n",
      "\n",
      "\n",
      "\n",
      "\u001B[1;30;42mDone!  :)\u001B[30m\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
